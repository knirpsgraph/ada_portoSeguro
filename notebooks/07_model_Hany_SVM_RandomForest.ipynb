{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T13:28:50.913482Z",
     "start_time": "2025-09-29T13:28:47.887997Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C_LOGREG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 407\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(+ feature_gate_scores.csv, feature_gate_meta.json)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 261\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m    260\u001b[0m     reports \u001b[38;5;241m=\u001b[39m ROOT\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreports_Hany\u001b[39m\u001b[38;5;124m\"\u001b[39m; reports\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 261\u001b[0m     models_to_test \u001b[38;5;241m=\u001b[39m get_models(\u001b[43mC_LOGREG\u001b[49m, RND)\n\u001b[0;32m    263\u001b[0m     df_all \u001b[38;5;241m=\u001b[39m load_and_save_data()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m    264\u001b[0m     n_rows_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_all)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'C_LOGREG' is not defined"
     ]
    }
   ],
   "source": [
    "import os, sys, json, warnings, time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, brier_score_loss, precision_recall_curve, accuracy_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# --- Repo root (notebook/script-safe)\n",
    "if \"__file__\" in globals():\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "else:\n",
    "    ROOT = Path.cwd() if Path.cwd().name not in (\"notebooks\",\"tools\",\"tests\") else Path.cwd().parent\n",
    "\n",
    "REPORTS_IN  = Path(os.getenv(\"REPORTS_IN\")  or (ROOT / \"reports_Hany\"))\n",
    "REPORTS_OUT = Path(os.getenv(\"REPORTS_OUT\") or (ROOT / \"reports_Hany\"))\n",
    "REPORTS_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sys.path.insert(0, str(ROOT))\n",
    "from src.data_loader import load_and_save_data\n",
    "from src.models import get_models\n",
    "\n",
    "# ZUSÄTZLICH: Importiere notwendige Preprocessing-Module\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ... (Runtime params und Helpers unverändert) ...\n",
    "\n",
    "SPEED = os.getenv(\"SPEED\", \"MEDIUM\").upper().strip()\n",
    "def speed_cfg():\n",
    "    cfg = dict(CV=5, N_EST=6000, EARLY_STOP=200, MODELS=[\"lgbm\",\"xgb\"], LR=0.03)\n",
    "    if SPEED == \"FAST\":\n",
    "        cfg.update(CV=3, N_EST=2000, EARLY_STOP=50, MODELS=[\"lgbm\"], LR=0.05)\n",
    "    elif SPEED == \"MEDIUM\":\n",
    "        cfg.update(CV=5, N_EST=4000, EARLY_STOP=100)\n",
    "    elif SPEED == \"FULL\":\n",
    "        cfg.update(CV=5, N_EST=8000, EARLY_STOP=300)\n",
    "    return cfg\n",
    "\n",
    "CFG        = speed_cfg()\n",
    "RND        = int(os.getenv(\"RND\", \"42\"))\n",
    "CV         = int(os.getenv(\"CV\", str(CFG[\"CV\"])))\n",
    "N_EST      = int(os.getenv(\"N_EST\", str(CFG[\"N_EST\"])))\n",
    "ESR        = int(os.getenv(\"EARLY_STOP\", str(CFG[\"EARLY_STOP\"])))\n",
    "MODELS     = [m.strip() for m in os.getenv(\"MODELS\", \",\".join(CFG[\"MODELS\"])).split(\",\") if m.strip()]\n",
    "IMB        = os.getenv(\"IMB\", \"spw\").lower()\n",
    "LR         = float(os.getenv(\"LR\", str(CFG[\"LR\"])))\n",
    "MEMBER     = os.getenv(\"MEMBER\", \"Hany\")\n",
    "\n",
    "def split_cols(cols):\n",
    "    cat = [c for c in cols if str(c).endswith(\"_cat\")]\n",
    "    bin_ = [c for c in cols if str(c).endswith(\"_bin\")]\n",
    "    num  = [c for c in cols if c not in cat and c not in bin_ and c != \"target\"]\n",
    "    return cat, bin_, num\n",
    "\n",
    "def fe_extras(X, selected):\n",
    "    X = X.copy()\n",
    "    if \"missing_count\" in selected:\n",
    "        X[\"missing_count\"] = X.isna().sum(axis=1)\n",
    "    if \"sum_all_bin\" in selected:\n",
    "        b = [c for c in X.columns if str(c).endswith(\"_bin\")]\n",
    "        X[\"sum_all_bin\"] = X[b].sum(axis=1) if b else 0\n",
    "    return X\n",
    "\n",
    "def prep_for_trees(X: pd.DataFrame, selected_cols):\n",
    "    X = fe_extras(X, selected_cols)\n",
    "    keep = [c for c in selected_cols if c in X.columns]\n",
    "    missing = [c for c in selected_cols if c not in X.columns]\n",
    "    if missing:\n",
    "        print(f\"[WARN] ignoring {len(missing)} missing selected feature(s).\")\n",
    "    X = X[keep].copy()\n",
    "    cat, _, _ = split_cols(X.columns)\n",
    "    for c in cat:\n",
    "        try: X[c] = X[c].astype(\"category\")\n",
    "        except: pass\n",
    "    return X, cat\n",
    "\n",
    "def scale_pos_weight(y):\n",
    "    pos = int((y==1).sum()); neg = int((y==0).sum())\n",
    "    return float(neg / max(pos,1))\n",
    "\n",
    "def xgb_train_predict(Xtr, ytr, Xva, yva, Xte=None, params=None, seed=RND, lr=LR):\n",
    "    import xgboost as xgb\n",
    "    params = dict(params or {})\n",
    "    p = {\n",
    "        \"objective\": \"binary:logistic\", \"eval_metric\": \"aucpr\",\n",
    "        \"tree_method\": params.pop(\"tree_method\", \"hist\"), \"eta\": params.pop(\"learning_rate\", lr),\n",
    "        \"max_depth\": int(params.pop(\"max_depth\", 6)), \"min_child_weight\": float(params.pop(\"min_child_weight\", 2.0)),\n",
    "        \"subsample\": float(params.pop(\"subsample\", 0.9)), \"colsample_bytree\": float(params.pop(\"colsample_bytree\", 0.9)),\n",
    "        \"lambda\": float(params.pop(\"reg_lambda\", 1.0)), \"alpha\": float(params.pop(\"reg_alpha\", 0.0)),\n",
    "        \"gamma\": float(params.pop(\"gamma\", 0.0)), \"seed\": int(params.pop(\"seed\", seed)), \"nthread\": -1,\n",
    "    }\n",
    "    if IMB == \"spw\": p[\"scale_pos_weight\"] = float(params.pop(\"scale_pos_weight\", 1.0))\n",
    "    meta = {\"use_ohe\": False, \"ohe_cols\": None}\n",
    "    cats = [c for c in Xtr.columns if str(c).endswith(\"_cat\")]\n",
    "    try:\n",
    "        dtr = xgb.DMatrix(Xtr, label=ytr, enable_categorical=True)\n",
    "        dva = xgb.DMatrix(Xva, label=yva, enable_categorical=True)\n",
    "        dte = xgb.DMatrix(Xte, enable_categorical=True) if Xte is not None else None\n",
    "        p[\"enable_categorical\"] = True\n",
    "    except Exception:\n",
    "        meta[\"use_ohe\"] = True\n",
    "        dXtr = pd.get_dummies(Xtr, columns=cats, dummy_na=True)\n",
    "        dXva = pd.get_dummies(Xva, columns=cats, dummy_na=True).reindex(columns=dXtr.columns, fill_value=0)\n",
    "        dtr = xgb.DMatrix(dXtr, label=ytr); dva = xgb.DMatrix(dXva, label=yva)\n",
    "        if Xte is not None: dXte = pd.get_dummies(Xte, columns=cats, dummy_na=True).reindex(columns=dXtr.columns, fill_value=0); dte = xgb.DMatrix(dXte)\n",
    "        meta[\"ohe_cols\"] = list(dXtr.columns)\n",
    "    booster = xgb.train(params=p, dtrain=dtr, num_boost_round=N_EST, evals=[(dva, \"valid\")], early_stopping_rounds=ESR, verbose_eval=False)\n",
    "    pred_va = booster.predict(dva, iteration_range=(0, (booster.best_iteration or N_EST)))\n",
    "    pred_te = booster.predict(dte, iteration_range=(0, (booster.best_iteration or N_EST))) if Xte is not None else None\n",
    "    imp = booster.get_score(importance_type=\"gain\")\n",
    "    if meta[\"use_ohe\"]: fi = pd.Series(imp, name=\"gain\").sort_values(ascending=False); fi.index.name = \"feature\"\n",
    "    else:\n",
    "        names = list(Xtr.columns); pairs = []\n",
    "        for k, v in imp.items():\n",
    "            if k.startswith(\"f\") and k[1:].isdigit(): idx = int(k[1:]); name = names[idx] if 0 <= idx < len(names) else k\n",
    "            else: name = k\n",
    "            pairs.append((name, v))\n",
    "        fi = pd.Series(dict(pairs), name=\"gain\").sort_values(ascending=False)\n",
    "    return booster, pred_va, pred_te, fi, meta\n",
    "def xgb_predict_time_ms_per_1k(booster, X, meta):\n",
    "    import xgboost as xgb\n",
    "    t0 = time.perf_counter()\n",
    "    if meta[\"use_ohe\"]:\n",
    "        cats = [c for c in X.columns if str(c).endswith(\"_cat\")]\n",
    "        dX = pd.get_dummies(X, columns=cats, dummy_na=True).reindex(columns=meta[\"ohe_cols\"], fill_value=0)\n",
    "        d = xgb.DMatrix(dX)\n",
    "    else:\n",
    "        d = xgb.DMatrix(X, enable_categorical=True)\n",
    "    _ = booster.predict(d, iteration_range=(0, (booster.best_iteration or N_EST)))\n",
    "    dt = time.perf_counter() - t0\n",
    "    return 1000 * dt / (len(X)/1000)\n",
    "\n",
    "def oof_cv(model_name, base_params, X, y, cat_cols):\n",
    "    skf = StratifiedKFold(n_splits=CV, shuffle=True, random_state=RND)\n",
    "    oof = np.zeros(len(y), dtype=float)\n",
    "\n",
    "    for tr, va in skf.split(X, y):\n",
    "        Xtr, Xva = X.iloc[tr], X.iloc[va]; ytr, yva = y.iloc[tr], y.iloc[va]\n",
    "\n",
    "        if model_name == \"lgbm\":\n",
    "            from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "            imb_kwargs = {\"is_unbalance\": True} if IMB == \"iso\" else {\"is_unbalance\": False}\n",
    "\n",
    "            defaults = {\n",
    "                \"n_estimators\": N_EST, \"random_state\": RND, \"n_jobs\": -1,\n",
    "                \"learning_rate\": LR, \"num_leaves\": 128, \"max_depth\": -1,\n",
    "                \"min_child_samples\": 20, \"subsample\": 0.9, \"colsample_bytree\": 0.9,\n",
    "                \"reg_lambda\": 1.0, \"reg_alpha\": 0.0, \"max_bin\": 511,\n",
    "                \"feature_pre_filter\": False, **imb_kwargs\n",
    "            }\n",
    "            if base_params: defaults.update(base_params)\n",
    "            clf = LGBMClassifier(**defaults)\n",
    "            clf.fit(\n",
    "                Xtr, ytr, eval_set=[(Xva, yva)], eval_metric=\"auc\",\n",
    "                categorical_feature=[c for c in cat_cols if c in Xtr.columns],\n",
    "                callbacks=[early_stopping(ESR), log_evaluation(0)]\n",
    "            )\n",
    "            oof[va] = clf.predict_proba(Xva)[:,1]\n",
    "        elif model_name == \"xgb\":\n",
    "            spw = scale_pos_weight(ytr) if IMB == \"spw\" else 1.0\n",
    "            _, pred_va, _, _, _ = xgb_train_predict(Xtr, ytr, Xva, yva, params={**(base_params or {}), \"scale_pos_weight\": spw})\n",
    "            oof[va] = pred_va\n",
    "        else: raise ValueError(\"Unknown model\")\n",
    "    pr = average_precision_score(y, oof); roc = roc_auc_score(y, oof); br = brier_score_loss(y, oof)\n",
    "    return dict(pr_auc=float(pr), roc_auc=float(roc), brier=float(br), oof=oof)\n",
    "\n",
    "def fit_final(model_name, params, Xtr, ytr, Xte, yte, cat_cols):\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(Xtr, ytr, test_size=0.1, stratify=ytr, random_state=RND)\n",
    "\n",
    "    if model_name == \"lgbm\":\n",
    "        from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "        imb_kwargs = {\"is_unbalance\": True} if IMB == \"iso\" else {\"is_unbalance\": False}\n",
    "        defaults = {\n",
    "            \"n_estimators\": N_EST, \"random_state\": RND, \"n_jobs\": -1,\n",
    "            \"learning_rate\": LR, \"num_leaves\": 128, \"max_depth\": -1,\n",
    "            \"min_child_samples\": 20, \"subsample\": 0.9, \"colsample_bytree\": 0.9,\n",
    "            \"reg_lambda\": 1.0, \"reg_alpha\": 0.0, \"max_bin\": 511,\n",
    "            \"feature_pre_filter\": False, **imb_kwargs\n",
    "        }\n",
    "        if params: defaults.update(params)\n",
    "        clf = LGBMClassifier(**defaults); t0 = time.perf_counter()\n",
    "        clf.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], eval_metric=\"auc\", categorical_feature=[c for c in cat_cols if c in X_tr.columns], callbacks=[early_stopping(ESR), log_evaluation(0)])\n",
    "        fit_time_s = time.perf_counter() - t0; t1 = time.perf_counter()\n",
    "        proba = clf.predict_proba(Xte)[:,1]; pred_ms_per_1k = 1000 * (time.perf_counter() - t1) / (len(Xte)/1000)\n",
    "        try: fi = pd.Series(clf.booster_.feature_importance(importance_type=\"gain\"), index=clf.booster_.feature_name(), name=\"gain\").sort_values(ascending=False)\n",
    "        except Exception: fi = pd.Series(clf.feature_importances_, index=Xtr.columns, name=\"split\").sort_values(ascending=False)\n",
    "        meta = {\n",
    "            \"encoder\": \"native(LGBM)\", \"best_iteration\": getattr(clf, \"best_iteration_\", None),\n",
    "            \"n_trees\": getattr(clf, \"n_estimators_\", None), \"fit_time_s\": float(fit_time_s),\n",
    "            \"predict_time_ms_per_1k\": float(pred_ms_per_1k), \"model_obj\": clf\n",
    "        }\n",
    "    else:\n",
    "        spw = scale_pos_weight(y_tr) if IMB == \"spw\" else 1.0\n",
    "        t0 = time.perf_counter()\n",
    "        booster, _, proba, fi, xmeta = xgb_train_predict(X_tr, y_tr, X_val, y_val, Xte, params={**(params or {}), \"scale_pos_weight\": spw})\n",
    "        fit_time_s = time.perf_counter() - t0\n",
    "        pred_ms_per_1k = xgb_predict_time_ms_per_1k(booster, Xte, xmeta)\n",
    "        meta = {\n",
    "            \"encoder\": \"native(XGB)\" if not xmeta[\"use_ohe\"] else \"OHE(XGB-fallback)\",\n",
    "            \"best_iteration\": getattr(booster, \"best_iteration\", None), \"n_trees\": getattr(booster, \"best_ntree_limit\", None),\n",
    "            \"fit_time_s\": float(fit_time_s), \"predict_time_ms_per_1k\": float(pred_ms_per_1k), \"model_obj\": booster\n",
    "        }\n",
    "    hold = dict(pr_auc=float(average_precision_score(yte, proba)), roc_auc=float(roc_auc_score(yte, proba)), brier=float(brier_score_loss(yte, proba)))\n",
    "    return proba, hold, fi, meta\n",
    "\n",
    "def save_pr_curve(y_true, proba, out_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    prec, rec, _ = precision_recall_curve(y_true, proba); ap = average_precision_score(y_true, proba)\n",
    "    plt.figure(figsize=(7,5)); plt.plot(rec, prec, label=f'AP={ap:.4f}')\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall')\n",
    "    plt.xlim([0,1]); plt.ylim([0,1]); plt.grid(True, alpha=0.3); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def save_calibration(y_true, proba, out_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    prob_true, prob_pred = calibration_curve(y_true, proba, n_bins=20, strategy=\"quantile\")\n",
    "    plt.figure(figsize=(6,6)); plt.plot([0,1],[0,1],'--',label='Perfect')\n",
    "    plt.plot(prob_pred, prob_true, marker='o', label='Model')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Observed'); plt.title('Calibration')\n",
    "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def save_top20_importance(fi: pd.Series, out_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    if fi is None or fi.empty: return\n",
    "    top = fi.head(20).iloc[::-1]\n",
    "    plt.figure(figsize=(8,6)); plt.barh(top.index, top.values)\n",
    "    plt.xlabel('Gain'); plt.title('Top-20 Feature Importance')\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def sample_params(model_name, n):\n",
    "    rng = np.random.default_rng(RND); out = []\n",
    "    if model_name == \"lgbm\":\n",
    "        for _ in range(n):\n",
    "            out.append(dict(\n",
    "                learning_rate=LR, num_leaves=int(rng.integers(64, 256)), max_depth=int(rng.integers(-1, 12)),\n",
    "                min_child_samples=int(rng.integers(10, 80)), subsample=float(rng.uniform(0.7, 1.0)),\n",
    "                colsample_bytree=float(rng.uniform(0.7, 1.0)), reg_lambda=float(rng.uniform(0.0, 2.0)),\n",
    "                reg_alpha=float(rng.uniform(0.0, 1.0)), is_unbalance=(IMB==\"iso\"),\n",
    "                max_bin=511, feature_pre_filter=False\n",
    "            ))\n",
    "    elif model_name == \"xgb\":\n",
    "        for _ in range(n):\n",
    "            out.append(dict(\n",
    "                learning_rate=LR, tree_method=\"hist\", max_depth=int(rng.integers(3, 10)),\n",
    "                min_child_weight=float(rng.uniform(1.0, 8.0)), subsample=float(rng.uniform(0.7, 1.0)),\n",
    "                colsample_bytree=float(rng.uniform(0.7, 1.0)), reg_lambda=float(rng.uniform(0.0, 2.0)),\n",
    "                reg_alpha=float(rng.uniform(0.0, 1.0)), gamma=float(rng.uniform(0.0, 2.0)),\n",
    "                scale_pos_weight=1.0\n",
    "            ))\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    reports = ROOT/\"reports_Hany\"; reports.mkdir(parents=True, exist_ok=True)\n",
    "    models_to_test = get_models(C_LOGREG, RND)\n",
    "\n",
    "    df_all = load_and_save_data().replace(-1, np.nan)\n",
    "    n_rows_total = len(df_all)\n",
    "    df = df_all\n",
    "    if N_SAMPLE and N_SAMPLE < len(df_all):\n",
    "        df = df_all.sample(N_SAMPLE, random_state=RND).sort_index()\n",
    "    y = df[\"target\"].astype(int)\n",
    "\n",
    "    X_tr_all, X_te_all, y_tr, y_te = train_test_split(\n",
    "        df.drop(columns=[\"target\"]), y, test_size=0.2, stratify=y, random_state=RND\n",
    "    )\n",
    "    df_tr = pd.concat([X_tr_all, y_tr], axis=1)\n",
    "    df_te = pd.concat([X_te_all, y_te], axis=1)\n",
    "\n",
    "    split_indices = {\"train\": df_tr.index.tolist(), \"test\": df_te.index.tolist()}\n",
    "    (reports/\"split_indices.json\").write_text(json.dumps(split_indices, indent=2))\n",
    "\n",
    "    configs = [\n",
    "        {\"name\":\"all_features\", \"drop_calc\":False, \"extra_drop\":[], \"add_extras\":False},\n",
    "        {\"name\":\"drop_calc+opt+extras\", \"drop_calc\":True, \"extra_drop\":[\"ps_ind_14\",\"ps_car_10_cat\"], \"add_extras\":True},\n",
    "        {\"name\":\"drop_calc_only\", \"drop_calc\":True, \"extra_drop\":[], \"add_extras\":False},\n",
    "        {\"name\":\"drop_calc+extras\", \"drop_calc\":True, \"extra_drop\":[], \"add_extras\":True},\n",
    "    ]\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for model_name, model_clf in models_to_test.items():\n",
    "        print(f\"Starte Kreuzvalidierung für Modell: {model_name}...\")\n",
    "        for cfg in configs:\n",
    "            print(f\"  Konfiguration: {cfg['name']}...\")\n",
    "            X_tr_cfg = make_feature_set(df_tr, drop_calc=cfg[\"drop_calc\"], extra_drop=cfg[\"extra_drop\"], add_extras=cfg[\"add_extras\"])\n",
    "\n",
    "            if isinstance(model_clf, (RandomForestClassifier, SVC, LGBMClassifier)):\n",
    "                auc_cv, pr_cv = cv_scores_ohe(X_tr_cfg, y_tr.loc[X_tr_cfg.index], model_clf, C=C_LOGREG, CV=CV)\n",
    "            elif TE_CAT:\n",
    "                auc_cv, pr_cv = cv_scores_te(X_tr_cfg, y_tr.loc[X_tr_cfg.index], C=C_LOGREG, CV=CV, clf=model_clf)\n",
    "            else:\n",
    "                auc_cv, pr_cv = cv_scores_ohe(X_tr_cfg, y_tr.loc[X_tr_cfg.index], C=C_LOGREG, CV=CV)\n",
    "\n",
    "            rows.append({\n",
    "                \"model_name\": model_name, \"config_name\": cfg[\"name\"], \"n_features\": int(X_tr_cfg.shape[1]),\n",
    "                \"cv_auc\": float(auc_cv), \"cv_pr_auc\": float(pr_cv),\n",
    "                \"drop_calc\": cfg[\"drop_calc\"], \"extra_drop\": cfg[\"extra_drop\"],\n",
    "                \"add_extras\": cfg[\"add_extras\"], \"te_cat\": TE_CAT\n",
    "            })\n",
    "\n",
    "    res = pd.DataFrame(rows).sort_values([\"cv_auc\",\"cv_pr_auc\"], ascending=False)\n",
    "    res_path = reports/\"feature_gate_scores.csv\"; res.to_csv(res_path, index=False)\n",
    "\n",
    "    best_cv = res.iloc[0].to_dict()\n",
    "    X_tr_best = make_feature_set(df_tr, drop_calc=best_cv[\"drop_calc\"], extra_drop=best_cv[\"extra_drop\"], add_extras=best_cv[\"add_extras\"])\n",
    "    X_te_best = make_feature_set(df_te, drop_calc=best_cv[\"drop_calc\"], extra_drop=best_cv[\"extra_drop\"], add_extras=best_cv[\"add_extras\"])\n",
    "\n",
    "    (reports/\"features_selected.csv\").write_text(\n",
    "        pd.Series(pd.Index(X_tr_best.columns), name=\"raw_feature\").to_csv(index=False)\n",
    "    )\n",
    "\n",
    "    best_model_name = best_cv[\"model_name\"]\n",
    "    best_model_clf = models_to_test[best_model_name]\n",
    "\n",
    "    if TE_CAT:\n",
    "        Xtr_cat, Xva_cat, Xtr_bin, Xva_bin, Xtr_num, Xva_num = _prep_te_blocks(X_tr_best, X_te_best)\n",
    "        tr_te, va_te = _kfold_target_encode(Xtr_cat, y_tr.loc[X_tr_best.index], Xva_cat, n_splits=CV, alpha=TE_ALPHA, seed=RND)\n",
    "        Xtr_fin = pd.concat([Xtr_num, Xtr_bin, tr_te], axis=1)\n",
    "        Xva_fin = pd.concat([Xva_num, Xva_bin, va_te], axis=1)\n",
    "        clf_best = models_to_test[best_model_name]\n",
    "        if hasattr(clf_best, 'C'): clf_best.C = C_LOGREG\n",
    "        clf_best.fit(Xtr_fin, y_tr.loc[X_tr_best.index])\n",
    "        proba_best = clf_best.predict_proba(Xva_fin)[:,1]\n",
    "    else:\n",
    "        cat_b, bin_b, num_b = split_cols(X_tr_best.columns)\n",
    "        pre_b = build_pre(cat_b, bin_b, num_b)\n",
    "        pipe_b = Pipeline([(\"pre\", pre_b), (\"clf\", best_model_clf)])\n",
    "        m_b = pipe_b.fit(X_tr_best, y_tr.loc[X_tr_best.index])\n",
    "        proba_best = m_b.predict_proba(X_te_best)[:,1]\n",
    "\n",
    "    y_true_best = y_te.loc[X_te_best.index]\n",
    "\n",
    "    X_tr_allF = make_feature_set(df_tr, drop_calc=False, extra_drop=[], add_extras=False)\n",
    "    X_te_allF = make_feature_set(df_te, drop_calc=False, extra_drop=[], add_extras=False)\n",
    "    catA, binA, numA = split_cols(X_tr_allF.columns)\n",
    "    pipe_all = Pipeline([(\"pre\", build_pre(catA, binA, numA)),\n",
    "                             (\"clf\", models_to_test[\"LogisticRegression\"])])\n",
    "    m_all = pipe_all.fit(X_tr_allF, y_tr.loc[X_tr_allF.index])\n",
    "    proba_all = m_all.predict_proba(X_te_allF)[:,1]\n",
    "\n",
    "    hold_auc_best = roc_auc_score(y_true_best, proba_best)\n",
    "    hold_pr_best = average_precision_score(y_true_best, proba_best)\n",
    "    hold_auc_all = roc_auc_score(y_te.loc[X_te_allF.index], proba_all)\n",
    "    hold_pr_all = average_precision_score(y_te.loc[X_te_allF.index], proba_all)\n",
    "\n",
    "    prec_b, rec_b, _ = precision_recall_curve(y_true_best, proba_best)\n",
    "    prec_a, rec_a, _ = precision_recall_curve(y_te.loc[X_te_allF.index], proba_all)\n",
    "\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(rec_b, prec_b, label=f\"Best ({best_model_name}, AP={hold_pr_best:.3f}, AUC={hold_auc_best:.3f})\")\n",
    "    plt.plot(rec_a, prec_a, label=f\"All-features (LR, AP={hold_pr_all:.3f}, AUC={hold_auc_all:.3f})\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Holdout Precision-Recall Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(reports/\"holdout_pr_curve.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    gbm_out = None\n",
    "    if GBM_CHECK:\n",
    "        catB, binB, numB = split_cols(X_tr_best.columns); preB = build_pre(catB, binB, numB)\n",
    "        XtrB = preB.fit_transform(X_tr_best); XvaB = preB.transform(X_te_best)\n",
    "        gbm_best = holdout_gbm_check(XtrB, y_tr.loc[X_tr_best.index], XvaB, y_true_best)\n",
    "        catC, binC, numC = split_cols(X_tr_allF.columns); preC = build_pre(catC, binC, numC)\n",
    "        XtrC = preC.fit_transform(X_tr_allF); XvaC = preC.transform(X_te_allF)\n",
    "        gbm_all = holdout_gbm_check(XtrC, y_tr.loc[X_tr_allF.index], XvaC, y_te.loc[X_te_allF.index])\n",
    "        gbm_out = {\"best\": gbm_best, \"all\": gbm_all}\n",
    "\n",
    "    meta = {\n",
    "        \"random_state\": RND, \"cv_splits\": CV, \"C\": C_LOGREG,\n",
    "        \"n_rows_total\": int(n_rows_total), \"sample_n\": int(len(df)),\n",
    "        \"te_cat\": TE_CAT, \"te_alpha\": TE_ALPHA, \"gbm_check\": bool(GBM_CHECK),\n",
    "        \"scores_path\": str(res_path),\n",
    "        \"features_path\": str(reports/\"features_selected.csv\"),\n",
    "        \"split_indices_path\": str(reports/\"split_indices.json\"),\n",
    "        \"pr_curve_path\": str(reports/\"holdout_pr_curve.png\"),\n",
    "        \"best_by_cv\": best_cv,\n",
    "        \"holdout_scores\": {\n",
    "            \"best_auc\": float(hold_auc_best), \"best_pr_auc\": float(hold_pr_best),\n",
    "            \"all_auc\": float(hold_auc_all), \"all_pr_auc\": float(hold_pr_all)\n",
    "        },\n",
    "        \"gbm_holdout\": gbm_out\n",
    "    }\n",
    "    (reports/\"feature_gate_meta.json\").write_text(json.dumps(meta, indent=2))\n",
    "\n",
    "    print(\"\\nFEATURE-GATE done.\")\n",
    "    print(f\"Train n={len(df_tr):,}, Holdout n={len(df_te):,}, CV={CV}, C={C_LOGREG}, TE_CAT={int(TE_CAT)}\")\n",
    "    print(\"Scores (CV):\\n\" + res.head(10).to_string(index=False))\n",
    "    print(f\"\\nHoldout (Best by CV): AUC={hold_auc_best:.4f}  PR-AUC={hold_pr_best:.4f}\")\n",
    "    print(f\"Holdout (All-features): AUC={hold_auc_all:.4f}  PR-AUC={hold_pr_all:.4f}\")\n",
    "    print(\"\\nArtifacts:\")\n",
    "    print(\"→ features_selected.csv\")\n",
    "    print(\"→ split_indices.json\")\n",
    "    print(\"→ holdout_pr_curve.png\")\n",
    "    print(\"(+ feature_gate_scores.csv, feature_gate_meta.json)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338bdc952d42b7d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T14:19:11.322343Z",
     "start_time": "2025-09-18T14:19:11.310287Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ddf6a-2bf9-4943-b523-d2bd05754d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (porto_seguro_env)",
   "language": "python",
   "name": "porto_seguro_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

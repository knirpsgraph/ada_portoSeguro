{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT=/Users/lucasbeseler/ada_portoSeguro\n",
      "PROFILE=MEDIUM (CV=5)\n",
      "Lade Datensatz aus dem Cache.\n",
      "[t] load & prep: 4.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 421\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDecision:   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreports/\u001b[33m'\u001b[39m\u001b[33mfinal_feature_decision.json\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 228\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# C einmal tunen\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m timer(\u001b[33m\"\u001b[39m\u001b[33mtune C (L1)\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m     C_L1 = \u001b[43mtune_C_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ml1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_n\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m150_000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m timer(\u001b[33m\"\u001b[39m\u001b[33mtune C (L2)\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    230\u001b[39m     C_L2 = tune_C_once(X, y, penalty=\u001b[33m\"\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m\"\u001b[39m, sample_n=\u001b[32m150_000\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 157\u001b[39m, in \u001b[36mtune_C_once\u001b[39m\u001b[34m(X, y, penalty, sample_n)\u001b[39m\n\u001b[32m    155\u001b[39m Xs = X.sample(\u001b[38;5;28mmin\u001b[39m(sample_n, \u001b[38;5;28mlen\u001b[39m(X)), random_state=RANDOM_STATE) \u001b[38;5;28;01mif\u001b[39;00m sample_n \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[32m    156\u001b[39m ys = y.loc[Xs.index]\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(grid.best_params_[\u001b[33m\"\u001b[39m\u001b[33mclf__C\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ada_portoSeguro/.venv/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ada_portoSeguro/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ada_portoSeguro/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ada_portoSeguro/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ada_portoSeguro/.venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ada_portoSeguro/.venv/lib/python3.13/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ada_portoSeguro/.venv/lib/python3.13/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ada_portoSeguro/.venv/lib/python3.13/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os, sys, time, json, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- ROOT robust (Notebook + Skript)\n",
    "if \"__file__\" in globals():\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "else:\n",
    "    CWD = Path.cwd()\n",
    "    ROOT = CWD.parent if CWD.name == \"notebooks\" else CWD\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "# optionales Theme\n",
    "try:\n",
    "    from src import theme\n",
    "    theme.set_project_theme()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from src.data_loader import load_and_save_data\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import RFECV, mutual_info_classif\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ------------ kleine Tools ------------\n",
    "def pbar(iterable, total=None, desc=\"\"):\n",
    "    total = total or (len(iterable) if hasattr(iterable, \"__len__\") else None)\n",
    "    cnt, start = 0, time.time()\n",
    "    for x in iterable:\n",
    "        yield x\n",
    "        cnt += 1\n",
    "        if total:\n",
    "            pct = int(100 * cnt / total)\n",
    "            bar = \"█\" * (pct // 4) + \"·\" * (25 - pct // 4)\n",
    "            rate = cnt / max(1e-9, time.time() - start)\n",
    "            print(f\"\\r{desc} [{bar}] {pct:3d}% {cnt}/{total} {rate:.1f} it/s\", end=\"\")\n",
    "    if total:\n",
    "        print(f\"\\r{desc} [{'█'*25}] 100% {cnt}/{total} done       \")\n",
    "\n",
    "from contextlib import contextmanager\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.perf_counter()\n",
    "    yield\n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"[t] {name}: {dt:.1f}s\")\n",
    "\n",
    "def gini_from_auc(auc): return 2*auc - 1\n",
    "def ensure_dir(p: Path): p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------ leichtes FE ------------\n",
    "def kaggle_style_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"missing_count\"] = df.isna().sum(axis=1)\n",
    "    bin_cols = [c for c in df.columns if c.endswith(\"_bin\")]\n",
    "    if bin_cols: df[\"sum_all_bin\"] = df[bin_cols].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "def add_missing_indicators(df):\n",
    "    df = df.copy()\n",
    "    for c in df.columns:\n",
    "        if c != \"target\" and df[c].isna().any():\n",
    "            df[f\"{c}_isna\"] = df[c].isna().astype(int)\n",
    "    return df\n",
    "\n",
    "def drop_near_zero_variance(df, thresh=1e-6):\n",
    "    keep = []\n",
    "    for c in df.columns:\n",
    "        if c == \"target\": continue\n",
    "        if not pd.api.types.is_numeric_dtype(df[c]): keep.append(c)\n",
    "        else:\n",
    "            if df[c].var(ddof=0) > thresh: keep.append(c)\n",
    "    return df[keep + ([\"target\"] if \"target\" in df.columns else [])]\n",
    "\n",
    "def drop_high_corr_numeric(df, thr=0.98):\n",
    "    num = [c for c in df.columns if c!=\"target\" and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if len(num)<2: return df\n",
    "    corr = df[num].corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    drop = [col for col in upper.columns if any(upper[col] > thr)]\n",
    "    return df.drop(columns=drop, errors=\"ignore\")\n",
    "\n",
    "def split_columns(cols):\n",
    "    cat = [c for c in cols if c.endswith(\"_cat\")]\n",
    "    bin_ = [c for c in cols if c.endswith(\"_bin\")]\n",
    "    other = [c for c in cols if (c not in cat and c not in bin_ and c != \"target\")]\n",
    "    return cat, bin_, other\n",
    "\n",
    "def _ohe_dense_minfreq():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, min_frequency=0.01)\n",
    "    except TypeError:\n",
    "        try:    return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "        except TypeError:\n",
    "                return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "def build_preprocessor(cat, bin_, num):\n",
    "    cat_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                         (\"ohe\", _ohe_dense_minfreq())])\n",
    "    num_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                         (\"sc\", StandardScaler())])\n",
    "    bin_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\"))])\n",
    "    return ColumnTransformer([(\"cat\", cat_pipe, cat),\n",
    "                              (\"bin\", bin_pipe, bin_),\n",
    "                              (\"num\", num_pipe, num)],\n",
    "                             remainder=\"drop\")\n",
    "\n",
    "def get_feature_names(pre, cat, bin_, num):\n",
    "    names = []\n",
    "    for name, trans, cols in pre.transformers_:\n",
    "        if name == \"cat\":\n",
    "            names.extend(list(trans.named_steps[\"ohe\"].get_feature_names_out(cols)))\n",
    "        elif name == \"bin\": names.extend(cols)\n",
    "        elif name == \"num\": names.extend(cols)\n",
    "    return names\n",
    "\n",
    "def cv_predict_proba(pipeline, X, y, n_splits=5, desc=\"CV\"):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    proba = np.zeros(len(y))\n",
    "    for (tr, te) in pbar(list(skf.split(X, y)), total=n_splits, desc=desc):\n",
    "        m = pipeline.fit(X.iloc[tr], y.iloc[tr])\n",
    "        proba[te] = m.predict_proba(X.iloc[te])[:,1]\n",
    "    return proba\n",
    "\n",
    "# ------------ einmal C tunen ------------\n",
    "def tune_C_once(X, y, penalty=\"l1\", sample_n=150_000):\n",
    "    Cs = np.logspace(-3, 1.5, 9)\n",
    "    cat, bin_, num = split_columns(X.columns)\n",
    "    pre = build_preprocessor(cat, bin_, num)\n",
    "    base = LogisticRegression(\n",
    "        penalty=penalty, solver=(\"saga\" if penalty==\"l1\" else \"lbfgs\"),\n",
    "        class_weight=\"balanced\", max_iter=4000, random_state=RANDOM_STATE, n_jobs=-1\n",
    "    )\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"clf\", base)])\n",
    "    grid = GridSearchCV(pipe, {\"clf__C\": Cs},\n",
    "                        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE),\n",
    "                        scoring=\"roc_auc\", n_jobs=-1)\n",
    "    Xs = X.sample(min(sample_n, len(X)), random_state=RANDOM_STATE) if sample_n else X\n",
    "    ys = y.loc[Xs.index]\n",
    "    grid.fit(Xs, ys)\n",
    "    return float(grid.best_params_[\"clf__C\"])\n",
    "\n",
    "# ------------ plotting ------------\n",
    "def save_auc_plot(summary_df, out_png):\n",
    "    fig = plt.figure(figsize=(9,5))\n",
    "    order = summary_df.sort_values(\"auc\", ascending=True)\n",
    "    plt.barh(order[\"feature_set\"], order[\"auc\"], color=\"#402D6F\")\n",
    "    for i, v in enumerate(order[\"auc\"]):\n",
    "        plt.text(v+0.001, i, f\"{v:.3f}\", va=\"center\", fontsize=9)\n",
    "    plt.xlabel(\"AUC\"); plt.title(\"Feature-Set Vergleich (CV-AUC)\")\n",
    "    plt.tight_layout(); fig.savefig(out_png, dpi=150); plt.close(fig)\n",
    "\n",
    "def save_vote_plot(vote_df, out_png, topn=40):\n",
    "    fig = plt.figure(figsize=(9,10))\n",
    "    dd = vote_df.sort_values(\"votes\", ascending=True).tail(topn)\n",
    "    plt.barh(dd[\"raw_feature\"], dd[\"votes\"], color=\"#402D6F\")\n",
    "    for i, v in enumerate(dd[\"votes\"]):\n",
    "        plt.text(v+0.02, i, f\"{v:.1f}\", va=\"center\", fontsize=8)\n",
    "    plt.xlabel(\"Votes (Methoden)\"); plt.title(f\"Feature-Votes (Top {topn})\")\n",
    "    plt.tight_layout(); fig.savefig(out_png, dpi=150); plt.close(fig)\n",
    "\n",
    "# ------------ OHE→Raw Mapping (fix) ------------\n",
    "def raw_from_ohe(name: str) -> str:\n",
    "    # NA-Flags behalten\n",
    "    if \"_isna\" in name:\n",
    "        return name\n",
    "    # echte OHE-Dummies: \"<col>_cat_<level>\" -> \"<col>_cat\"\n",
    "    if \"_cat_\" in name:\n",
    "        return name.split(\"_cat_\")[0] + \"_cat\"\n",
    "    # numerische/binäre bleiben 1:1 (z.B. ps_calc_12, ps_ind_17_bin)\n",
    "    return name\n",
    "\n",
    "# ------------ Hauptlauf ------------\n",
    "def main():\n",
    "    # Profile\n",
    "    PROFILE = os.environ.get(\"FS_PROFILE\", \"FAST\")\n",
    "    if PROFILE == \"FAST\":\n",
    "        CV_SPLITS = 3; RUN_RFECV = False; RUN_PI = False\n",
    "        N_BASE, N_KAG, N_RFE, N_PI = 100_000, 100_000, 60_000, 60_000\n",
    "    elif PROFILE == \"FULL\":\n",
    "        CV_SPLITS = 5; RUN_RFECV = True; RUN_PI = True\n",
    "        N_BASE = N_KAG = N_RFE = N_PI = None\n",
    "    else:  # MEDIUM\n",
    "        CV_SPLITS = 5; RUN_RFECV = True; RUN_PI = True\n",
    "        N_BASE, N_KAG, N_RFE, N_PI = 200_000, 200_000, 150_000, 150_000\n",
    "\n",
    "    DROP_EXTRA = True\n",
    "    EXTRA_TO_DROP = [\"ps_ind_14\", \"ps_car_10_cat\"]  # oft gedroppt\n",
    "\n",
    "    reports = ROOT / \"reports\"\n",
    "    ensure_dir(reports)\n",
    "\n",
    "    print(f\"ROOT={ROOT}\")\n",
    "    print(f\"PROFILE={PROFILE} (CV={CV_SPLITS})\")\n",
    "\n",
    "    # Daten\n",
    "    with timer(\"load & prep\"):\n",
    "        df = load_and_save_data(); assert df is not None and len(df)>0\n",
    "        df = df.replace(-1, np.nan)\n",
    "        y = df[\"target\"].astype(int)\n",
    "        X = df.drop(columns=[\"target\"])\n",
    "        X = kaggle_style_features(X)\n",
    "        X = add_missing_indicators(X)\n",
    "        Xc = pd.concat([X, y], axis=1)\n",
    "        Xc = drop_near_zero_variance(Xc)\n",
    "        Xc = drop_high_corr_numeric(Xc)\n",
    "        X = Xc.drop(columns=[\"target\"])\n",
    "\n",
    "    # C einmal tunen\n",
    "    with timer(\"tune C (L1)\"):\n",
    "        C_L1 = tune_C_once(X, y, penalty=\"l1\", sample_n=150_000)\n",
    "    with timer(\"tune C (L2)\"):\n",
    "        C_L2 = tune_C_once(X, y, penalty=\"l2\", sample_n=150_000)\n",
    "\n",
    "    # Modelle (fixes C)\n",
    "    lr_l1 = LogisticRegression(penalty=\"l1\", solver=\"saga\", C=C_L1,\n",
    "                               class_weight=\"balanced\", max_iter=4000, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "    lr_l2 = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", C=C_L2,\n",
    "                               class_weight=\"balanced\", max_iter=4000, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "    hgb = HistGradientBoostingClassifier(learning_rate=0.08, max_leaf_nodes=31, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Helper\n",
    "    def mkpipe(Xcols, clf):\n",
    "        c,b,n = split_columns(Xcols)\n",
    "        pre = build_preprocessor(c,b,n)\n",
    "        return Pipeline([(\"pre\", pre), (\"clf\", clf)]), pre, (c,b,n)\n",
    "\n",
    "    # Baseline (L1)\n",
    "    print(\"baseline (L1 fixed C)…\")\n",
    "    Xb = X.sample(min(len(X), N_BASE), random_state=RANDOM_STATE) if N_BASE else X\n",
    "    yb = y.loc[Xb.index]\n",
    "    pipe_b, pre_b, (cb,bb,nb) = mkpipe(Xb.columns, lr_l1)\n",
    "    with timer(\"CV baseline\"):\n",
    "        proba_b = cv_predict_proba(pipe_b, Xb, yb, CV_SPLITS, \"CV baseline\")\n",
    "        auc_b = roc_auc_score(yb, proba_b)\n",
    "    rep_base = {\"feature_set\":\"Baseline (L1 tuned once)\",\"auc\":auc_b,\"gini\":gini_from_auc(auc_b)}\n",
    "    # Top-K\n",
    "    model_b = pipe_b.fit(Xb, yb)\n",
    "    fn_b = get_feature_names(model_b.named_steps[\"pre\"], cb, bb, nb)\n",
    "    coef_b = model_b.named_steps[\"clf\"].coef_.ravel()\n",
    "    imp_b = (pd.DataFrame({\"feature\":fn_b,\"coef\":coef_b,\"abs_coef\":np.abs(coef_b)})\n",
    "             .sort_values(\"abs_coef\", ascending=False).head(80))\n",
    "    imp_b.to_csv(reports/\"topcoef_logreg_l1_baseline.csv\", index=False)\n",
    "\n",
    "    # Kaggle-Style (drop calc + optional extra)\n",
    "    print(\"kaggle-style …\")\n",
    "    drop_calc = [c for c in X.columns if c.startswith(\"ps_calc_\")]\n",
    "    Xk = X.drop(columns=drop_calc, errors=\"ignore\")\n",
    "    if DROP_EXTRA: Xk = Xk.drop(columns=[c for c in EXTRA_TO_DROP if c in Xk.columns], errors=\"ignore\")\n",
    "    Xk_eval = Xk.sample(min(len(Xk), N_KAG), random_state=RANDOM_STATE) if N_KAG else Xk\n",
    "    yk_eval = y.loc[Xk_eval.index]\n",
    "    pipe_k, pre_k, (ck,bk,nk) = mkpipe(Xk_eval.columns, lr_l1)\n",
    "    with timer(\"CV kaggle\"):\n",
    "        proba_k = cv_predict_proba(pipe_k, Xk_eval, yk_eval, CV_SPLITS, \"CV kaggle\")\n",
    "        auc_k = roc_auc_score(yk_eval, proba_k)\n",
    "    rep_kaggle = {\"feature_set\":\"Kaggle-Style (L1 tuned once)\",\"auc\":auc_k,\"gini\":gini_from_auc(auc_k)}\n",
    "\n",
    "    # RFECV (optional)\n",
    "    if RUN_RFECV:\n",
    "        print(\"rfecv …\")\n",
    "        Xr = X.sample(min(len(X), N_RFE), random_state=RANDOM_STATE) if N_RFE else X\n",
    "        yr = y.loc[Xr.index]\n",
    "        cr, br, nr = split_columns(Xr.columns)\n",
    "        pre_r = build_preprocessor(cr, br, nr)\n",
    "        Xr_mat = pre_r.fit_transform(Xr, yr)\n",
    "        fn_r = get_feature_names(pre_r, cr, br, nr)\n",
    "        rfecv = RFECV(\n",
    "            estimator=LogisticRegression(penalty=\"l1\", solver=\"saga\", C=C_L1,\n",
    "                                         class_weight=\"balanced\", max_iter=4000, n_jobs=-1, random_state=RANDOM_STATE),\n",
    "            step=0.2, cv=3, scoring=\"roc_auc\", n_jobs=-1\n",
    "        )\n",
    "        with timer(\"RFECV fit\"):\n",
    "            rfecv.fit(Xr_mat, yr)\n",
    "        mask = rfecv.support_\n",
    "        sel_names = [f for f,keep in zip(fn_r, mask) if keep]\n",
    "        pd.Series(sel_names, name=\"selected_feature\").to_csv(reports/\"rfe_selected_features.csv\", index=False)\n",
    "        # CV mit Auswahl\n",
    "        skf = StratifiedKFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        proba_rfe = np.zeros(len(yr))\n",
    "        for (tr, te) in pbar(list(skf.split(Xr_mat[:,mask], yr)), total=CV_SPLITS, desc=\"CV rfe\"):\n",
    "            clf = LogisticRegression(penalty=\"l1\", solver=\"saga\", C=C_L1,\n",
    "                                     class_weight=\"balanced\", max_iter=4000, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "            clf.fit(Xr_mat[tr][:,mask], yr.iloc[tr])\n",
    "            proba_rfe[te] = clf.predict_proba(Xr_mat[te][:,mask])[:,1]\n",
    "        auc_rfe = roc_auc_score(yr, proba_rfe)\n",
    "        rep_rfe = {\"feature_set\":f\"RFECV ({mask.sum()} feats)\",\"auc\":auc_rfe,\"gini\":gini_from_auc(auc_rfe)}\n",
    "    else:\n",
    "        rep_rfe = {\"feature_set\":\"RFECV (skipped)\",\"auc\":np.nan,\"gini\":np.nan}\n",
    "        sel_names = []\n",
    "\n",
    "    # Mutual Information (auf Baseline-Sample)\n",
    "    print(\"mutual information …\")\n",
    "    pre_mi = build_preprocessor(cb, bb, nb)\n",
    "    with timer(\"MI\"):\n",
    "        Xmat_full = pre_mi.fit_transform(Xb, yb)\n",
    "        fn_mi = get_feature_names(pre_mi, cb, bb, nb)\n",
    "        mi_vals = mutual_info_classif(Xmat_full, yb, random_state=RANDOM_STATE)\n",
    "        mi_rank = (pd.DataFrame({\"feature\":fn_mi,\"mi\":mi_vals})\n",
    "                   .sort_values(\"mi\", ascending=False).head(80))\n",
    "        mi_rank.to_csv(reports/\"mi_rank_baseline.csv\", index=False)\n",
    "\n",
    "    # HGB + Permutation Importance (optional)\n",
    "    if RUN_PI:\n",
    "        print(\"histgradientboosting + PI …\")\n",
    "        Xpi = X.sample(min(len(X), N_PI), random_state=RANDOM_STATE) if N_PI else X\n",
    "        ypi = y.loc[Xpi.index]\n",
    "        cp, bp, np_ = split_columns(Xpi.columns)\n",
    "        pre_h = build_preprocessor(cp, bp, np_)\n",
    "        pipe_hgb = Pipeline([(\"pre\", pre_h), (\"clf\", hgb)])\n",
    "        with timer(\"CV hgb\"):\n",
    "            proba_hgb = cv_predict_proba(pipe_hgb, Xpi, ypi, CV_SPLITS, \"CV hgb\")\n",
    "            auc_hgb = roc_auc_score(ypi, proba_hgb)\n",
    "        model_hgb = pipe_hgb.fit(Xpi, ypi)\n",
    "        pre_fit = model_hgb.named_steps[\"pre\"]\n",
    "        fn_h = get_feature_names(pre_fit, cp, bp, np_)\n",
    "        Xpi_mat = pre_fit.transform(Xpi)\n",
    "        with timer(\"Permutation Importance\"):\n",
    "            pi = permutation_importance(model_hgb.named_steps[\"clf\"], Xpi_mat, ypi,\n",
    "                                        n_repeats=3, random_state=RANDOM_STATE, n_jobs=-1, scoring=\"roc_auc\")\n",
    "        pi_rank = (pd.DataFrame({\"feature\":fn_h,\"pi\":pi.importances_mean})\n",
    "                   .sort_values(\"pi\", ascending=False).head(80))\n",
    "        pi_rank.to_csv(reports/\"permutation_importance_hgb.csv\", index=False)\n",
    "        rep_hgb = {\"feature_set\":\"HGB + PI\",\"auc\":auc_hgb,\"gini\":gini_from_auc(auc_hgb)}\n",
    "    else:\n",
    "        pi_rank = pd.DataFrame(columns=[\"feature\",\"pi\"])\n",
    "        rep_hgb = {\"feature_set\":\"HGB + PI (skipped)\",\"auc\":np.nan,\"gini\":np.nan}\n",
    "\n",
    "    # Ridge (L2) fix\n",
    "    print(\"ridge (L2 fixed C) …\")\n",
    "    def mkpipe(Xcols, clf):\n",
    "        c,b,n = split_columns(Xcols)\n",
    "        pre = build_preprocessor(c,b,n)\n",
    "        return Pipeline([(\"pre\", pre), (\"clf\", clf)]), pre, (c,b,n)\n",
    "    pipe_ridge, pre_ridge, (c2,b2,n2) = mkpipe(X.columns, lr_l2)\n",
    "    with timer(\"CV ridge\"):\n",
    "        proba_ridge = cv_predict_proba(pipe_ridge, X, y, CV_SPLITS, \"CV ridge\")\n",
    "        auc_ridge = roc_auc_score(y, proba_ridge)\n",
    "    rep_ridge = {\"feature_set\":\"Ridge (L2 tuned once)\",\"auc\":auc_ridge,\"gini\":gini_from_auc(auc_ridge)}\n",
    "    # Coef-Ranking\n",
    "    model_ridge = pipe_ridge.fit(X, y)\n",
    "    fn_ridge = get_feature_names(model_ridge.named_steps[\"pre\"], c2,b2,n2)\n",
    "    coef_r = model_ridge.named_steps[\"clf\"].coef_.ravel()\n",
    "    ridge_rank = (pd.DataFrame({\"feature\":fn_ridge,\"coef\":coef_r,\"abs_coef\":np.abs(coef_r)})\n",
    "                  .sort_values(\"abs_coef\", ascending=False).head(80))\n",
    "    ridge_rank.to_csv(reports/\"topcoef_ridge.csv\", index=False)\n",
    "\n",
    "    # --- stabile Kandidaten (OHE) & Votes je Roh-Feature\n",
    "    top_l1 = set(imp_b[\"feature\"])\n",
    "    top_mi = set(mi_rank[\"feature\"])\n",
    "    top_pi = set(pi_rank[\"feature\"]) if not pi_rank.empty else set()\n",
    "    top_rfe = set(sel_names)\n",
    "\n",
    "    from collections import Counter\n",
    "    vote_ohe = Counter()\n",
    "    for s in [top_l1, top_mi, top_pi, top_rfe]:\n",
    "        for f in s: vote_ohe[f] += 1\n",
    "\n",
    "    stable_ohe = [f for f, v in vote_ohe.items() if v >= 2]\n",
    "    pd.Series(stable_ohe, name=\"feature\").to_csv(reports/\"feature_candidates_stable_ohe.csv\", index=False)\n",
    "\n",
    "    vote_raw = Counter()\n",
    "    for f, v in vote_ohe.items():\n",
    "        vote_raw[raw_from_ohe(f)] += v\n",
    "    votes_df = pd.DataFrame(sorted(vote_raw.items(), key=lambda x: (-x[1], x[0])),\n",
    "                            columns=[\"raw_feature\",\"votes\"])\n",
    "    votes_df.to_csv(reports/\"feature_votes_raw.csv\", index=False)\n",
    "\n",
    "    # Schwelle: env steuert, sonst auto (>=4 wenn viele, sonst >=2)\n",
    "    th_env = os.environ.get(\"FS_VOTE_THRESHOLD\")\n",
    "    THRESHOLD = int(th_env) if th_env is not None else (4 if len(votes_df)>=80 else 2)\n",
    "    selected_raw = votes_df.loc[votes_df[\"votes\"]>=THRESHOLD, \"raw_feature\"].tolist()\n",
    "    pd.Series(selected_raw, name=\"raw_feature\").to_csv(reports/\"selected_features_raw.csv\", index=False)\n",
    "\n",
    "    # Summary + Plots\n",
    "    summary = pd.DataFrame([rep_base, rep_kaggle, rep_rfe, rep_hgb, rep_ridge])\\\n",
    "                .sort_values(\"auc\", ascending=False)\n",
    "    summary.to_csv(reports/\"feature_set_cv_summary.csv\", index=False)\n",
    "    save_auc_plot(summary, reports/\"feature_set_cv_summary.png\")\n",
    "    save_vote_plot(votes_df, reports/\"feature_votes_raw.png\", topn=40)\n",
    "\n",
    "    # Entscheidung schreiben\n",
    "    decision = {\n",
    "        \"profile\": PROFILE, \"cv_splits\": CV_SPLITS,\n",
    "        \"C_L1\": C_L1, \"C_L2\": C_L2,\n",
    "        \"threshold\": THRESHOLD,\n",
    "        \"selected_raw_n\": len(selected_raw),\n",
    "        \"selected_raw\": selected_raw[:200],\n",
    "        \"summary_auc\": summary.to_dict(orient=\"records\")\n",
    "    }\n",
    "    (reports/\"final_feature_decision.json\").write_text(json.dumps(decision, indent=2))\n",
    "    (reports/\"final_feature_decision.txt\").write_text(\n",
    "        \"Empfehlung: nutze diese Roh-Variablen (regel: votes >= %d)\\n\\n%s\\n\" %\n",
    "        (THRESHOLD, \"\\n\".join(selected_raw))\n",
    "    )\n",
    "\n",
    "    print(\"\\n== CV performance (AUC/Gini) ==\")\n",
    "    print(summary.to_string(index=False))\n",
    "    print(f\"\\nSelected raw features: {len(selected_raw)}  -> {reports/'selected_features_raw.csv'}\")\n",
    "    print(f\"Votes plot: {reports/'feature_votes_raw.png'}\")\n",
    "    print(f\"AUC plot:   {reports/'feature_set_cv_summary.png'}\")\n",
    "    print(f\"Decision:   {reports/'final_feature_decision.json'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT = /Users/lucasbeseler/ada_portoSeguro\n",
      "PROFILE=MEDIUM  (CV=5)\n",
      "Lade Datensatz aus dem Cache.\n",
      "[t] load & prep: 5.0s\n",
      "baseline (L1 tuned)…\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os, sys, time, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Robust: funktioniert als .py **und** im Notebook\n",
    "if \"__file__\" in globals():\n",
    "    ROOT = Path(__file__).resolve().parents[1]  # <repo>/\n",
    "else:\n",
    "    CWD = Path.cwd()\n",
    "    ROOT = CWD.parent if CWD.name == \"notebooks\" else CWD  # <repo>/notebooks -> <repo>/\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "# optional: sanity check\n",
    "print(\"ROOT =\", ROOT)\n",
    "assert (ROOT / \"src\").exists(), \"src/ nicht gefunden – stimmt dein Repo-Pfad?\"\n",
    "\n",
    "# optionales Theme\n",
    "try:\n",
    "    from src import theme\n",
    "    theme.set_project_theme()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from src.data_loader import load_and_save_data\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import RFECV, mutual_info_classif\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt  # Plot als PNG speichern\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# --- kleine Tools\n",
    "def pbar(iterable, total=None, desc=\"\"):\n",
    "    total = total or (len(iterable) if hasattr(iterable, \"__len__\") else None)\n",
    "    count, start = 0, time.time()\n",
    "    for x in iterable:\n",
    "        yield x\n",
    "        count += 1\n",
    "        if total:\n",
    "            pct = int(100 * count / total)\n",
    "            bar = \"█\" * (pct // 4) + \"·\" * (25 - pct // 4)\n",
    "            rate = count / max(1e-9, time.time() - start)\n",
    "            print(f\"\\r{desc} [{bar}] {pct:3d}% {count}/{total} {rate:.1f} it/s\", end=\"\")\n",
    "    if total:\n",
    "        print(f\"\\r{desc} [{'█'*25}] 100% {count}/{total} done        \")\n",
    "\n",
    "from contextlib import contextmanager\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.perf_counter()\n",
    "    yield\n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"[t] {name}: {dt:.1f}s\")\n",
    "\n",
    "def gini_from_auc(auc: float) -> float:\n",
    "    return 2.0 * auc - 1.0\n",
    "\n",
    "# --- leichtes FE\n",
    "def kaggle_style_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"missing_count\"] = df.isna().sum(axis=1)\n",
    "    bin_cols = [c for c in df.columns if c.endswith(\"_bin\")]\n",
    "    if bin_cols:\n",
    "        df[\"sum_all_bin\"] = df[bin_cols].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "def add_missing_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in df.columns:\n",
    "        if c != \"target\" and df[c].isna().any():\n",
    "            df[f\"{c}_isna\"] = df[c].isna().astype(int)\n",
    "    return df\n",
    "\n",
    "def drop_near_zero_variance(df: pd.DataFrame, thresh=1e-6) -> pd.DataFrame:\n",
    "    keep = []\n",
    "    for c in df.columns:\n",
    "        if c == \"target\": \n",
    "            continue\n",
    "        if not pd.api.types.is_numeric_dtype(df[c]): \n",
    "            keep.append(c)\n",
    "        else:\n",
    "            if df[c].var(ddof=0) > thresh:\n",
    "                keep.append(c)\n",
    "    return df[keep + ([\"target\"] if \"target\" in df.columns else [])]\n",
    "\n",
    "def drop_high_corr_numeric(df: pd.DataFrame, thr=0.98) -> pd.DataFrame:\n",
    "    num_cols = [c for c in df.columns if c != \"target\" and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if len(num_cols) < 2: \n",
    "        return df\n",
    "    corr = df[num_cols].corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    to_drop = [col for col in upper.columns if any(upper[col] > thr)]\n",
    "    return df.drop(columns=to_drop, errors=\"ignore\")\n",
    "\n",
    "def split_columns(cols):\n",
    "    cat = [c for c in cols if c.endswith(\"_cat\")]\n",
    "    bin_ = [c for c in cols if c.endswith(\"_bin\")]\n",
    "    other = [c for c in cols if (c not in cat and c not in bin_ and c != \"target\")]\n",
    "    return cat, bin_, other\n",
    "\n",
    "def _ohe_dense_minfreq():\n",
    "    # robust über sklearn-Versionen\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, min_frequency=0.01)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "        except TypeError:\n",
    "            return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "def build_preprocessor(cat_cols, bin_cols, num_cols) -> ColumnTransformer:\n",
    "    cat_pipeline = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                             (\"ohe\", _ohe_dense_minfreq())])\n",
    "    num_pipeline = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                             (\"scaler\", StandardScaler())])\n",
    "    bin_pipeline = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\"))])\n",
    "    return ColumnTransformer(\n",
    "        [(\"cat\", cat_pipeline, cat_cols),\n",
    "         (\"bin\", bin_pipeline, bin_cols),\n",
    "         (\"num\", num_pipeline, num_cols)],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "def get_feature_names(pre: ColumnTransformer, cat_cols, bin_cols, num_cols):\n",
    "    names = []\n",
    "    for name, trans, cols in pre.transformers_:\n",
    "        if name == \"cat\":\n",
    "            names.extend(list(trans.named_steps[\"ohe\"].get_feature_names_out(cols)))\n",
    "        elif name == \"bin\":\n",
    "            names.extend(cols)\n",
    "        elif name == \"num\":\n",
    "            names.extend(cols)\n",
    "    return names\n",
    "\n",
    "def cv_predict_proba_manual(pipeline: Pipeline, X, y, n_splits=5, desc=\"CV\"):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    proba = np.zeros(len(y), dtype=float)\n",
    "    for (tr, te) in pbar(list(skf.split(X, y)), total=n_splits, desc=desc):\n",
    "        model = pipeline.fit(X.iloc[tr], y.iloc[tr])\n",
    "        proba[te] = model.predict_proba(X.iloc[te])[:, 1]\n",
    "    return proba\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_auc_plot(summary_df: pd.DataFrame, out_png: Path):\n",
    "    fig = plt.figure(figsize=(7.5, 4.5))\n",
    "    order = summary_df.sort_values(\"auc\", ascending=True)\n",
    "    plt.barh(order[\"feature_set\"], order[\"auc\"])\n",
    "    for i, v in enumerate(order[\"auc\"]):\n",
    "        plt.text(v + 0.001, i, f\"{v:.3f}\", va=\"center\", fontsize=9)\n",
    "    plt.xlabel(\"AUC\")\n",
    "    plt.title(\"Feature-Set Vergleich (CV-AUC)\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_png, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "def main():\n",
    "    # --- Profile (anpassbar)\n",
    "    PROFILE = os.environ.get(\"FS_PROFILE\", \"MEDIUM\")  # FAST / MEDIUM / FULL\n",
    "\n",
    "    if PROFILE == \"FAST\":\n",
    "        BASELINE_SAMPLE_N = 100_000\n",
    "        KAGGLE_SAMPLE_N   = 100_000\n",
    "        RFE_SAMPLE_N      = 60_000\n",
    "        PI_SAMPLE_N       = 60_000\n",
    "        CV_SPLITS         = 3\n",
    "        RUN_RFECV         = False\n",
    "        RUN_PI            = False\n",
    "    elif PROFILE == \"FULL\":\n",
    "        BASELINE_SAMPLE_N = None\n",
    "        KAGGLE_SAMPLE_N   = None\n",
    "        RFE_SAMPLE_N      = None\n",
    "        PI_SAMPLE_N       = None\n",
    "        CV_SPLITS         = 5\n",
    "        RUN_RFECV         = True\n",
    "        RUN_PI            = True\n",
    "    else:  # MEDIUM\n",
    "        BASELINE_SAMPLE_N = 200_000\n",
    "        KAGGLE_SAMPLE_N   = 200_000\n",
    "        RFE_SAMPLE_N      = 150_000\n",
    "        PI_SAMPLE_N       = 150_000\n",
    "        CV_SPLITS         = 5\n",
    "        RUN_RFECV         = True\n",
    "        RUN_PI            = True\n",
    "\n",
    "    # Optional: zusätzliche Drops (manche Kaggle-Lösungen)\n",
    "    DROP_EXTRA = True\n",
    "    EXTRA_TO_DROP = [\"ps_ind_14\", \"ps_car_10_cat\"]\n",
    "\n",
    "    reports_dir = ROOT / \"reports\"\n",
    "    ensure_dir(reports_dir)\n",
    "\n",
    "    # --- Daten laden & vorbereiten\n",
    "    print(f\"PROFILE={PROFILE}  (CV={CV_SPLITS})\")\n",
    "    with timer(\"load & prep\"):\n",
    "        df = load_and_save_data()\n",
    "        assert df is not None and len(df) > 0, \"Kein DataFrame erhalten.\"\n",
    "        df = df.replace(-1, np.nan)\n",
    "        y = df[\"target\"].astype(int)\n",
    "        X = df.drop(columns=[\"target\"])\n",
    "        X = kaggle_style_features(X)\n",
    "        X = add_missing_indicators(X)\n",
    "        Xc = pd.concat([X, y], axis=1)\n",
    "        Xc = drop_near_zero_variance(Xc)\n",
    "        Xc = drop_high_corr_numeric(Xc)\n",
    "        X = Xc.drop(columns=[\"target\"])\n",
    "\n",
    "    # --- Modelle (L1/L2 getuned via CV)\n",
    "    cv5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    l1cv = LogisticRegressionCV(\n",
    "        Cs=np.logspace(-3, 2, 10), cv=cv5, scoring=\"roc_auc\",\n",
    "        penalty=\"l1\", solver=\"saga\", class_weight=\"balanced\",\n",
    "        max_iter=4000, n_jobs=-1, refit=True\n",
    "    )\n",
    "    l2cv = LogisticRegressionCV(\n",
    "        Cs=np.logspace(-3, 2, 10), cv=cv5, scoring=\"roc_auc\",\n",
    "        penalty=\"l2\", solver=\"lbfgs\", class_weight=\"balanced\",\n",
    "        max_iter=4000, n_jobs=-1, refit=True\n",
    "    )\n",
    "    hgb = HistGradientBoostingClassifier(\n",
    "        learning_rate=0.08, max_leaf_nodes=31, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    # --- Baseline (L1 getuned)\n",
    "    print(\"baseline (L1 tuned)…\")\n",
    "    Xb = X.sample(BASELINE_SAMPLE_N, random_state=RANDOM_STATE) if BASELINE_SAMPLE_N else X\n",
    "    yb = y.loc[Xb.index]\n",
    "    cb, bb, nb = split_columns(Xb.columns)\n",
    "    pre_b = build_preprocessor(cb, bb, nb)\n",
    "    pipe_b = Pipeline([(\"pre\", pre_b), (\"clf\", l1cv)])\n",
    "    with timer(\"CV baseline\"):\n",
    "        proba_b = cv_predict_proba_manual(pipe_b, Xb, yb, n_splits=CV_SPLITS, desc=\"CV baseline\")\n",
    "        auc_b = roc_auc_score(yb, proba_b)\n",
    "    rep_base = {\"feature_set\": \"Baseline (L1 tuned)\", \"auc\": auc_b, \"gini\": gini_from_auc(auc_b)}\n",
    "    # Top-K (auf Full-Fit)\n",
    "    with timer(\"fit coef baseline (L1 tuned)\"):\n",
    "        model_b = pipe_b.fit(Xb, yb)\n",
    "        fn_b = get_feature_names(model_b.named_steps[\"pre\"], cb, bb, nb)\n",
    "        coef_b = model_b.named_steps[\"clf\"].coef_.ravel()\n",
    "        imp_b = (pd.DataFrame({\"feature\": fn_b, \"coef\": coef_b, \"abs_coef\": np.abs(coef_b)})\n",
    "                 .sort_values(\"abs_coef\", ascending=False).head(60))\n",
    "        imp_b.to_csv(reports_dir / \"topcoef_logreg_l1_tuned_baseline.csv\", index=False)\n",
    "\n",
    "    # --- Kaggle-Style (drop ps_calc_* [+ optional extra])\n",
    "    print(\"kaggle-style …\")\n",
    "    drop_calc = [c for c in X.columns if c.startswith(\"ps_calc_\")]\n",
    "    Xk = X.drop(columns=drop_calc, errors=\"ignore\")\n",
    "    if DROP_EXTRA:\n",
    "        Xk = Xk.drop(columns=[c for c in EXTRA_TO_DROP if c in Xk.columns], errors=\"ignore\")\n",
    "    yk = y.loc[Xk.index]\n",
    "    ck, bk, nk = split_columns(Xk.columns)\n",
    "    pre_k = build_preprocessor(ck, bk, nk)\n",
    "    pipe_k = Pipeline([(\"pre\", pre_k), (\"clf\", l1cv)])\n",
    "    with timer(\"CV kaggle\"):\n",
    "        Xk_eval = Xk.sample(KAGGLE_SAMPLE_N, random_state=RANDOM_STATE) if KAGGLE_SAMPLE_N else Xk\n",
    "        yk_eval = y.loc[Xk_eval.index]\n",
    "        proba_k = cv_predict_proba_manual(pipe_k, Xk_eval, yk_eval, n_splits=CV_SPLITS, desc=\"CV kaggle\")\n",
    "        auc_k = roc_auc_score(yk_eval, proba_k)\n",
    "    rep_kaggle = {\"feature_set\": \"Kaggle-Style (L1 tuned)\", \"auc\": auc_k, \"gini\": gini_from_auc(auc_k)}\n",
    "\n",
    "    # --- RFECV (L1, auf Sample)\n",
    "    if RUN_RFECV:\n",
    "        print(\"rfecv …\")\n",
    "        Xr = X.sample(RFE_SAMPLE_N, random_state=RANDOM_STATE) if RFE_SAMPLE_N else X\n",
    "        yr = y.loc[Xr.index]\n",
    "        cr, br, nr = split_columns(Xr.columns)\n",
    "        pre_r = build_preprocessor(cr, br, nr)\n",
    "        Xr_mat = pre_r.fit_transform(Xr, yr)\n",
    "        fn_r = get_feature_names(pre_r, cr, br, nr)\n",
    "        rfecv = RFECV(\n",
    "            estimator=LogisticRegression(penalty=\"l1\", solver=\"saga\", max_iter=4000,\n",
    "                                         class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=-1),\n",
    "            step=0.2, cv=3, scoring=\"roc_auc\", n_jobs=-1\n",
    "        )\n",
    "        with timer(\"RFECV fit\"):\n",
    "            rfecv.fit(Xr_mat, yr)\n",
    "        mask = rfecv.support_\n",
    "        sel_names = [f for f, keep in zip(fn_r, mask) if keep]\n",
    "        pd.Series(sel_names, name=\"selected_feature\").to_csv(reports_dir / \"rfe_selected_features.csv\", index=False)\n",
    "        # Out-of-fold auf selek. Matrix\n",
    "        skf = StratifiedKFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        proba_rfe = np.zeros(len(yr))\n",
    "        for (tr, te) in pbar(list(skf.split(Xr_mat[:, mask], yr)), total=CV_SPLITS, desc=\"CV rfe\"):\n",
    "            clf = LogisticRegression(penalty=\"l1\", solver=\"saga\", max_iter=4000,\n",
    "                                     class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=-1)\n",
    "            clf.fit(Xr_mat[tr][:, mask], yr.iloc[tr])\n",
    "            proba_rfe[te] = clf.predict_proba(Xr_mat[te][:, mask])[:, 1]\n",
    "        auc_rfe = roc_auc_score(yr, proba_rfe)\n",
    "        rep_rfe = {\"feature_set\": f\"RFECV ({mask.sum()} feats)\", \"auc\": auc_rfe, \"gini\": gini_from_auc(auc_rfe)}\n",
    "    else:\n",
    "        rep_rfe = {\"feature_set\": \"RFECV (skipped)\", \"auc\": np.nan, \"gini\": np.nan}\n",
    "        sel_names = []\n",
    "\n",
    "    # --- Mutual Information (Baseline-View)\n",
    "    print(\"mutual information …\")\n",
    "    pre_mi = build_preprocessor(cb, bb, nb)\n",
    "    with timer(\"MI\"):\n",
    "        Xmat_full = pre_mi.fit_transform(Xb, yb)\n",
    "        fn_mi = get_feature_names(pre_mi, cb, bb, nb)\n",
    "        mi_vals = mutual_info_classif(Xmat_full, yb, random_state=RANDOM_STATE)\n",
    "        mi_rank = (pd.DataFrame({\"feature\": fn_mi, \"mi\": mi_vals})\n",
    "                   .sort_values(\"mi\", ascending=False).head(60))\n",
    "        mi_rank.to_csv(reports_dir / \"mi_rank_baseline.csv\", index=False)\n",
    "\n",
    "    # --- HGB + Permutation Importance (optional)\n",
    "    if RUN_PI:\n",
    "        print(\"histgradientboosting + PI …\")\n",
    "        Xpi = X.sample(PI_SAMPLE_N, random_state=RANDOM_STATE) if PI_SAMPLE_N else X\n",
    "        ypi = y.loc[Xpi.index]\n",
    "        cp, bp, np_ = split_columns(Xpi.columns)\n",
    "        pre_h = build_preprocessor(cp, bp, np_)\n",
    "        pipe_hgb = Pipeline([(\"pre\", pre_h), (\"clf\", hgb)])\n",
    "        with timer(\"CV hgb\"):\n",
    "            proba_hgb = cv_predict_proba_manual(pipe_hgb, Xpi, ypi, n_splits=CV_SPLITS, desc=\"CV hgb\")\n",
    "            auc_hgb = roc_auc_score(ypi, proba_hgb)\n",
    "        model_hgb = pipe_hgb.fit(Xpi, ypi)\n",
    "        pre_fit = model_hgb.named_steps[\"pre\"]\n",
    "        fn_h = get_feature_names(pre_fit, cp, bp, np_)\n",
    "        Xpi_mat = pre_fit.transform(Xpi)\n",
    "        with timer(\"Permutation Importance\"):\n",
    "            pi = permutation_importance(model_hgb.named_steps[\"clf\"], Xpi_mat, ypi,\n",
    "                                        n_repeats=3, random_state=RANDOM_STATE, n_jobs=-1,\n",
    "                                        scoring=\"roc_auc\")\n",
    "        pi_rank = (pd.DataFrame({\"feature\": fn_h, \"pi\": pi.importances_mean})\n",
    "                   .sort_values(\"pi\", ascending=False).head(60))\n",
    "        pi_rank.to_csv(reports_dir / \"permutation_importance_hgb.csv\", index=False)\n",
    "        rep_hgb = {\"feature_set\": \"HGB + PI\", \"auc\": auc_hgb, \"gini\": gini_from_auc(auc_hgb)}\n",
    "    else:\n",
    "        pi_rank = pd.DataFrame(columns=[\"feature\", \"pi\"])\n",
    "        rep_hgb = {\"feature_set\": \"HGB + PI (skipped)\", \"auc\": np.nan, \"gini\": np.nan}\n",
    "\n",
    "    # --- Ridge (L2 getuned)\n",
    "    print(\"ridge (L2 tuned) …\")\n",
    "    c2, b2, n2 = split_columns(X.columns)\n",
    "    pre_ridge = build_preprocessor(c2, b2, n2)\n",
    "    pipe_ridge = Pipeline([(\"pre\", pre_ridge), (\"clf\", l2cv)])\n",
    "    with timer(\"CV ridge\"):\n",
    "        proba_ridge = cv_predict_proba_manual(pipe_ridge, X, y, n_splits=CV_SPLITS, desc=\"CV ridge\")\n",
    "        auc_ridge = roc_auc_score(y, proba_ridge)\n",
    "    rep_ridge = {\"feature_set\": \"Ridge (L2 tuned)\", \"auc\": auc_ridge, \"gini\": gini_from_auc(auc_ridge)}\n",
    "    with timer(\"fit coef ridge\"):\n",
    "        model_ridge = pipe_ridge.fit(X, y)\n",
    "        fn_ridge = get_feature_names(model_ridge.named_steps[\"pre\"], c2, b2, n2)\n",
    "        coef_r = model_ridge.named_steps[\"clf\"].coef_.ravel()\n",
    "        ridge_rank = (pd.DataFrame({\"feature\": fn_ridge, \"coef\": coef_r, \"abs_coef\": np.abs(coef_r)})\n",
    "                      .sort_values(\"abs_coef\", ascending=False).head(60))\n",
    "        ridge_rank.to_csv(reports_dir / \"topcoef_ridge_tuned.csv\", index=False)\n",
    "\n",
    "    # --- Stabile Kandidatenliste (Schnittmenge aus Methoden)\n",
    "    top_l1 = set(imp_b[\"feature\"])\n",
    "    top_mi = set(mi_rank[\"feature\"].head(60))\n",
    "    top_pi = set(pi_rank[\"feature\"].head(60)) if not pi_rank.empty else set()\n",
    "    top_rfe = set(sel_names)\n",
    "    def in_methods(f):\n",
    "        return int(f in top_l1) + int(f in top_mi) + int(f in top_pi) + int(f in top_rfe)\n",
    "    all_feats = list(top_l1 | top_mi | top_pi | top_rfe)\n",
    "    stable = [f for f in all_feats if in_methods(f) >= 2]\n",
    "    pd.Series(stable, name=\"feature\").to_csv(reports_dir / \"feature_candidates_stable.csv\", index=False)\n",
    "    print(f\"stable candidates: {len(stable)} -> {reports_dir/'feature_candidates_stable.csv'}\")\n",
    "\n",
    "    # --- Summary + Plot\n",
    "    summary = pd.DataFrame([rep_base, rep_kaggle, rep_rfe, rep_hgb, rep_ridge]).sort_values(\"auc\", ascending=False)\n",
    "    summary.to_csv(reports_dir / \"feature_set_cv_summary.csv\", index=False)\n",
    "    save_auc_plot(summary, reports_dir / \"feature_set_cv_summary.png\")\n",
    "\n",
    "    print(\"\\n== CV performance (AUC/Gini) ==\")\n",
    "    print(summary.to_string(index=False))\n",
    "    print(f\"\\nReports & Plot -> {reports_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Datensatz lokal...\n",
      "Datensatz erfolgreich geladen\n",
      "\n",
      "FEATURE-GATE fertig.\n",
      "Train n=200,000, Holdout n=50,000, CV=3, C=1.0\n",
      "Scores (CV):\n",
      "                 name  n_features   cv_auc  cv_pr_auc  drop_calc                 extra_drop  add_extras\n",
      "drop_calc+opt+extras          37 0.620888   0.059965       True [ps_ind_14, ps_car_10_cat]        True\n",
      "    drop_calc+extras          39 0.620864   0.059968       True                         []        True\n",
      "      drop_calc_only          37 0.620800   0.059986       True                         []       False\n",
      "        all_features          57 0.619775   0.059835      False                         []       False\n",
      "\n",
      "Holdout drop_calc+opt+extras:   AUC=0.6325  PR-AUC=0.0651\n",
      "Holdout all_features: AUC=0.6284  PR-AUC=0.0645\n",
      "\n",
      "Gewählt: drop_calc+opt+extras\n",
      "→ Spalten: /Users/lucasbeseler/ada_portoSeguro/reports/features_selected.csv\n",
      "→ Scores:  /Users/lucasbeseler/ada_portoSeguro/reports/feature_gate_scores.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Fast Feature-Gate zwischen EDA und ML: vergleicht Feature-Sets per CrossValidation (CV), bestätigt auf Holdout,\n",
    "# wählt das beste Set, speichert Auswahl + Scores und zeigt Kurzreport in der Konsole.\n",
    "\n",
    "import os, sys, json, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Repo-ROOT robust (Notebook/Skript)\n",
    "if \"__file__\" in globals():\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "else:\n",
    "    CWD = Path.cwd(); ROOT = CWD.parent if CWD.name == \"notebooks\" else CWD\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from src.data_loader import load_and_save_data\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "RND = 42\n",
    "\n",
    "# --- Helpers (kurz & pragmatisch)\n",
    "def ohe_fallback():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"infrequent_if_exist\", min_frequency=0.01, sparse_output=True)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
    "        except TypeError:\n",
    "            return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "def split_cols(cols):\n",
    "    cat = [c for c in cols if c.endswith(\"_cat\")]\n",
    "    bin_ = [c for c in cols if c.endswith(\"_bin\")]\n",
    "    num  = [c for c in cols if c not in cat and c not in bin_ and c != \"target\"]\n",
    "    return cat, bin_, num\n",
    "\n",
    "def fe_simple(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = X.copy()\n",
    "    X[\"missing_count\"] = X.isna().sum(axis=1)\n",
    "    b = [c for c in X.columns if c.endswith(\"_bin\")]\n",
    "    if b: X[\"sum_all_bin\"] = X[b].sum(axis=1)\n",
    "    return X\n",
    "\n",
    "def build_pre(cat, bin_, num):\n",
    "    cat_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")), (\"ohe\", ohe_fallback())])\n",
    "    num_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")), (\"sc\", StandardScaler())])\n",
    "    bin_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\"))])\n",
    "    return ColumnTransformer([(\"cat\", cat_pipe, cat), (\"bin\", bin_pipe, bin_), (\"num\", num_pipe, num)], remainder=\"drop\")\n",
    "\n",
    "def make_feature_set(df, drop_calc=True, extra_drop=None, add_extras=True, drop_groups=None):\n",
    "    X = df.drop(columns=[\"target\"], errors=\"ignore\").copy().replace(-1, np.nan)\n",
    "    if drop_calc:\n",
    "        X = X.drop(columns=[c for c in X.columns if c.startswith(\"ps_calc_\")], errors=\"ignore\")\n",
    "    if extra_drop:\n",
    "        X = X.drop(columns=[c for c in extra_drop if c in X.columns], errors=\"ignore\")\n",
    "    extras_cols = []\n",
    "    if add_extras:\n",
    "        X = fe_simple(X); extras_cols = [\"missing_count\", \"sum_all_bin\"]\n",
    "    if drop_groups:\n",
    "        cat, bin_, num = split_cols(X.columns)\n",
    "        if drop_groups.get(\"cat\"):   X = X.drop(columns=cat, errors=\"ignore\")\n",
    "        if drop_groups.get(\"bin\"):   X = X.drop(columns=bin_, errors=\"ignore\")\n",
    "        if drop_groups.get(\"num\"):   X = X.drop(columns=num, errors=\"ignore\")\n",
    "        if drop_groups.get(\"extras\"): X = X.drop(columns=[c for c in extras_cols if c in X.columns], errors=\"ignore\")\n",
    "    return X\n",
    "\n",
    "def cv_scores(X, y, C=1.0, CV=3, seed=RND):\n",
    "    cat, bin_, num = split_cols(X.columns)\n",
    "    pre  = build_pre(cat, bin_, num)\n",
    "    clf  = LogisticRegression(penalty=\"l2\", solver=\"saga\", C=C, class_weight=\"balanced\", max_iter=4000, random_state=seed)\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)])\n",
    "    skf = StratifiedKFold(n_splits=CV, shuffle=True, random_state=seed)\n",
    "    proba = np.zeros(len(y), dtype=float)\n",
    "    for tr, te in skf.split(X, y):\n",
    "        m = pipe.fit(X.iloc[tr], y.iloc[tr])\n",
    "        proba[te] = m.predict_proba(X.iloc[te])[:, 1]\n",
    "    return roc_auc_score(y, proba), average_precision_score(y, proba)\n",
    "\n",
    "# --- Main\n",
    "\n",
    "def main():\n",
    "    CV = int(os.getenv(\"CV\", \"3\"))                 # schnell & stabil\n",
    "    C  = float(os.getenv(\"C\", \"1.0\"))              # LogReg-Stärke\n",
    "    N  = int(os.getenv(\"TRAIN_SAMPLE_N\", \"250000\")) # Default: schneller Teil-Sample\n",
    "\n",
    "    reports = ROOT/\"reports\"; reports.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = load_and_save_data().replace(-1, np.nan)\n",
    "    if N and N < len(df):\n",
    "        df = df.sample(N, random_state=RND).sort_index()\n",
    "    y  = df[\"target\"].astype(int)\n",
    "\n",
    "    # Holdout zur Bestätigung\n",
    "    X_tr_all, X_te_all, y_tr, y_te = train_test_split(df.drop(columns=[\"target\"]), y, test_size=0.2, stratify=y, random_state=RND)\n",
    "    df_tr = pd.concat([X_tr_all, y_tr], axis=1)\n",
    "    df_te = pd.concat([X_te_all, y_te], axis=1)\n",
    "\n",
    "    # Kandidaten (knapp, schnell)\n",
    "    configs = [\n",
    "        {\"name\":\"all_features\",                 \"drop_calc\":False, \"extra_drop\":[],                         \"add_extras\":False},\n",
    "        {\"name\":\"drop_calc+opt+extras\",        \"drop_calc\":True,  \"extra_drop\":[\"ps_ind_14\",\"ps_car_10_cat\"], \"add_extras\":True},\n",
    "        {\"name\":\"drop_calc_only\",              \"drop_calc\":True,  \"extra_drop\":[],                         \"add_extras\":False},\n",
    "        {\"name\":\"drop_calc+extras\",            \"drop_calc\":True,  \"extra_drop\":[],                         \"add_extras\":True},\n",
    "    ]\n",
    "\n",
    "    rows = []\n",
    "    for cfg in configs:\n",
    "        X_tr = make_feature_set(df_tr, drop_calc=cfg[\"drop_calc\"], extra_drop=cfg[\"extra_drop\"], add_extras=cfg[\"add_extras\"])\n",
    "        auc_cv, pr_cv = cv_scores(X_tr, y_tr.loc[X_tr.index], C=C, CV=CV)\n",
    "        rows.append({\"name\":cfg[\"name\"], \"n_features\":int(X_tr.shape[1]), \"cv_auc\":float(auc_cv), \"cv_pr_auc\":float(pr_cv),\n",
    "                     \"drop_calc\":cfg[\"drop_calc\"], \"extra_drop\":cfg[\"extra_drop\"], \"add_extras\":cfg[\"add_extras\"]})\n",
    "\n",
    "    res = pd.DataFrame(rows).sort_values([\"cv_auc\",\"cv_pr_auc\"], ascending=False)\n",
    "    res_path = reports/\"feature_gate_scores.csv\"; res.to_csv(res_path, index=False)\n",
    "\n",
    "    # Bestes Set via CV, dann auf Holdout bestätigen (Fallback: all_features, wenn schlechter)\n",
    "    best = res.iloc[0].to_dict()\n",
    "    X_tr_best = make_feature_set(df_tr, drop_calc=best[\"drop_calc\"], extra_drop=best[\"extra_drop\"], add_extras=best[\"add_extras\"]) \n",
    "    X_te_best = make_feature_set(df_te, drop_calc=best[\"drop_calc\"], extra_drop=best[\"extra_drop\"], add_extras=best[\"add_extras\"]) \n",
    "\n",
    "    # Finales Fit auf Train, Eval auf Holdout\n",
    "    cat, bin_, num = split_cols(X_tr_best.columns)\n",
    "    pipe = Pipeline([(\"pre\", build_pre(cat, bin_, num)), (\"clf\", LogisticRegression(penalty=\"l2\", solver=\"saga\", C=C, class_weight=\"balanced\", max_iter=4000, random_state=RND))])\n",
    "    m = pipe.fit(X_tr_best, y_tr.loc[X_tr_best.index])\n",
    "    proba_hold = m.predict_proba(X_te_best)[:,1]\n",
    "    hold_auc = roc_auc_score(y_te.loc[X_te_best.index], proba_hold)\n",
    "    hold_pr  = average_precision_score(y_te.loc[X_te_best.index], proba_hold)\n",
    "\n",
    "    # Gegenprobe: all_features auf Holdout\n",
    "    X_tr_all = make_feature_set(df_tr, drop_calc=False, extra_drop=[], add_extras=False)\n",
    "    X_te_all = make_feature_set(df_te, drop_calc=False, extra_drop=[], add_extras=False)\n",
    "    catA, binA, numA = split_cols(X_tr_all.columns)\n",
    "    pipe_all = Pipeline([(\"pre\", build_pre(catA, binA, numA)), (\"clf\", LogisticRegression(penalty=\"l2\", solver=\"saga\", C=C, class_weight=\"balanced\", max_iter=4000, random_state=RND))])\n",
    "    m_all = pipe_all.fit(X_tr_all, y_tr.loc[X_tr_all.index])\n",
    "    proba_hold_all = m_all.predict_proba(X_te_all)[:,1]\n",
    "    hold_auc_all = roc_auc_score(y_te.loc[X_te_all.index], proba_hold_all)\n",
    "    hold_pr_all  = average_precision_score(y_te.loc[X_te_all.index], proba_hold_all)\n",
    "\n",
    "    # Falls Bestes auf Holdout schlechter als alle Features um >0.002 → fallback\n",
    "    if (hold_auc + 1e-12) < (hold_auc_all - 0.002) or (hold_pr + 1e-12) < (hold_pr_all - 0.002):\n",
    "        chosen = {\"name\":\"all_features\", \"drop_calc\":False, \"extra_drop\":[], \"add_extras\":False, \"cv_auc\":None, \"cv_pr_auc\":None,\n",
    "                  \"holdout_auc\":float(hold_auc_all), \"holdout_pr_auc\":float(hold_pr_all)}\n",
    "        X_choose = X_tr_all.columns\n",
    "    else:\n",
    "        chosen = {\"name\":best[\"name\"], \"drop_calc\":best[\"drop_calc\"], \"extra_drop\":best[\"extra_drop\"], \"add_extras\":best[\"add_extras\"],\n",
    "                  \"cv_auc\":float(best[\"cv_auc\"]), \"cv_pr_auc\":float(best[\"cv_pr_auc\"]), \"holdout_auc\":float(hold_auc), \"holdout_pr_auc\":float(hold_pr)}\n",
    "        X_choose = X_tr_best.columns\n",
    "\n",
    "    feat_path = reports/\"features_selected.csv\"\n",
    "    pd.Series(pd.Index(X_choose), name=\"raw_feature\").to_csv(feat_path, index=False)\n",
    "\n",
    "    meta = {\"random_state\":RND, \"cv_splits\":CV, \"C\":C, \"n_rows\":int(len(df)), \"sample_n\":int(len(df)),\n",
    "            \"scores_path\":str(res_path), \"features_path\":str(feat_path), \"chosen\":chosen}\n",
    "    (reports/\"feature_gate_meta.json\").write_text(json.dumps(meta, indent=2))\n",
    "\n",
    "    # --- Console-Report (kurz)\n",
    "    print(\"\\nFEATURE-GATE fertig.\")\n",
    "    print(f\"Train n={len(df_tr):,}, Holdout n={len(df_te):,}, CV={CV}, C={C}\")\n",
    "    print(\"Scores (CV):\\n\", res.head(6).to_string(index=False))\n",
    "    print(f\"\\nHoldout {best['name']}:   AUC={hold_auc:.4f}  PR-AUC={hold_pr:.4f}\")\n",
    "    print(f\"Holdout all_features: AUC={hold_auc_all:.4f}  PR-AUC={hold_pr_all:.4f}\")\n",
    "    print(f\"\\nGewählt: {chosen['name']}\")\n",
    "    print(f\"→ Spalten: {feat_path}\")\n",
    "    print(f\"→ Scores:  {res_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Datensatz aus dem Cache.\n",
      "\n",
      "a) Was macht das Skript?\n",
      "- lädt den Datensatz, ersetzt -1→NaN\n",
      "- dropt ps_calc_* (+ optional ps_ind_14, ps_car_10_cat)\n",
      "- fügt missing_count & sum_all_bin hinzu\n",
      "- OHE für *_cat, Impute/Scale für numerische, Impute für binär\n",
      "- trainiert LogReg L2 und misst CV-AUC\n",
      "- speichert:\n",
      "  • Modell: /Users/lucasbeseler/ada_portoSeguro/models/kagglepreset_logreg_l2.joblib\n",
      "  • Featureliste: /Users/lucasbeseler/ada_portoSeguro/reports/selected_features_kagglepreset.csv\n",
      "  • Meta/Entscheidung: /Users/lucasbeseler/ada_portoSeguro/reports/kagglepreset_decision.json\n",
      "\n",
      "b) Was sagen die Ergebnisse?\n",
      "- AUC (CV=3, N=595,212): 0.6266\n",
      "- Interpretation: Der Kaggle-Preset (calc raus + einfache FE + OHE) trägt.\n",
      "- Die Datei selected_features_kagglepreset.csv ist jetzt eine schlanke Feature-Basis für weitere Modelle.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Final, klein & schnell: Kaggle-Preset (calc drop + Extras) + LogReg L2 + Summary-Text\n",
    "\n",
    "import os, sys, json, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- ROOT robust (Notebook + Skript)\n",
    "if \"__file__\" in globals():\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "else:\n",
    "    CWD = Path.cwd()\n",
    "    ROOT = CWD.parent if CWD.name == \"notebooks\" else CWD\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from src.data_loader import load_and_save_data\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "\n",
    "RND = 42\n",
    "\n",
    "def ohe_fallback():\n",
    "    # robust gegen verschiedene scikit-learn Versionen\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, min_frequency=0.01)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "        except TypeError:\n",
    "            return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "def split_cols(cols):\n",
    "    cat = [c for c in cols if c.endswith(\"_cat\")]\n",
    "    bin_ = [c for c in cols if c.endswith(\"_bin\")]\n",
    "    num  = [c for c in cols if (c not in cat and c not in bin_ and c != \"target\")]\n",
    "    return cat, bin_, num\n",
    "\n",
    "def fe_simple(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = X.copy()\n",
    "    X[\"missing_count\"] = X.isna().sum(axis=1)\n",
    "    bin_cols = [c for c in X.columns if c.endswith(\"_bin\")]\n",
    "    if bin_cols:\n",
    "        X[\"sum_all_bin\"] = X[bin_cols].sum(axis=1)\n",
    "    return X\n",
    "\n",
    "def build_pre(cat, bin_, num):\n",
    "    cat_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                         (\"ohe\", ohe_fallback())])\n",
    "    num_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                         (\"sc\", StandardScaler())])\n",
    "    bin_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\"))])\n",
    "    return ColumnTransformer([(\"cat\", cat_pipe, cat),\n",
    "                              (\"bin\", bin_pipe, bin_),\n",
    "                              (\"num\", num_pipe, num)], remainder=\"drop\")\n",
    "\n",
    "def main():\n",
    "    # einfache Steuerung per Env (optional)\n",
    "    CV = int(os.getenv(\"CV\", \"3\"))             # 3-fold ist schnell & stabil\n",
    "    C  = float(os.getenv(\"C\", \"1.0\"))          # L2-Stärke\n",
    "    N  = int(os.getenv(\"TRAIN_SAMPLE_N\", \"0\")) # 0 = alles, sonst z.B. 200000\n",
    "\n",
    "    reports = ROOT / \"reports\"; reports.mkdir(parents=True, exist_ok=True)\n",
    "    models  = ROOT / \"models\";  models.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # a) Daten laden & vorbereiten\n",
    "    df = load_and_save_data()\n",
    "    df = df.replace(-1, np.nan)\n",
    "    y  = df[\"target\"].astype(int)\n",
    "    X  = df.drop(columns=[\"target\"])\n",
    "\n",
    "    # ps_calc_* + optionale Extras droppen\n",
    "    calc_cols = [c for c in X.columns if c.startswith(\"ps_calc_\")]\n",
    "    extra_drop = [c for c in [\"ps_ind_14\", \"ps_car_10_cat\"] if c in X.columns]\n",
    "    X = X.drop(columns=calc_cols + extra_drop, errors=\"ignore\")\n",
    "\n",
    "    # Zusatzfeatures\n",
    "    X = fe_simple(X)\n",
    "\n",
    "    # optional sample\n",
    "    if N:\n",
    "        X = X.sample(min(N, len(X)), random_state=RND)\n",
    "        y = y.loc[X.index]\n",
    "\n",
    "    # Guard: keine calc-Spalten mehr?\n",
    "    assert not any(c.startswith(\"ps_calc_\") for c in X.columns), \"ps_calc_* nicht komplett entfernt\"\n",
    "\n",
    "    # Preproz + Modell\n",
    "    cat, bin_, num = split_cols(X.columns)\n",
    "    pre  = build_pre(cat, bin_, num)\n",
    "    clf  = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", C=C,\n",
    "                              class_weight=\"balanced\", max_iter=4000, random_state=RND)\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)])\n",
    "\n",
    "    # CV-AUC\n",
    "    skf = StratifiedKFold(n_splits=CV, shuffle=True, random_state=RND)\n",
    "    proba = np.zeros(len(y), dtype=float)\n",
    "    for tr, te in skf.split(X, y):\n",
    "        m = pipe.fit(X.iloc[tr], y.iloc[tr])\n",
    "        proba[te] = m.predict_proba(X.iloc[te])[:, 1]\n",
    "    auc = roc_auc_score(y, proba)\n",
    "\n",
    "    # Final fit + speichern\n",
    "    final_model = pipe.fit(X, y)\n",
    "    joblib.dump(final_model, models / \"kagglepreset_logreg_l2.joblib\")\n",
    "\n",
    "    # Featureliste (Rohspalten) + Meta\n",
    "    feat_path = reports / \"selected_features_kagglepreset.csv\"\n",
    "    pd.Series(X.columns, name=\"raw_feature\").to_csv(feat_path, index=False)\n",
    "\n",
    "    meta = {\n",
    "        \"cv_auc\": float(auc),\n",
    "        \"n_rows\": int(len(y)),\n",
    "        \"cv_splits\": CV,\n",
    "        \"C\": C,\n",
    "        \"dropped\": {\"ps_calc_*\": True, \"extra\": extra_drop},\n",
    "        \"extras_added\": [\"missing_count\", \"sum_all_bin\"],\n",
    "        \"model_path\": str(models / \"kagglepreset_logreg_l2.joblib\"),\n",
    "        \"features_path\": str(feat_path)\n",
    "    }\n",
    "    (reports / \"kagglepreset_decision.json\").write_text(json.dumps(meta, indent=2))\n",
    "\n",
    "    # --- Abschluss: erklärender Text (a/b) auf Deutsch ---\n",
    "    print()\n",
    "    print(\"a) Was macht das Skript?\")\n",
    "    print(\"- lädt den Datensatz, ersetzt -1→NaN\")\n",
    "    print(\"- dropt ps_calc_* (+ optional ps_ind_14, ps_car_10_cat)\")\n",
    "    print(\"- fügt missing_count & sum_all_bin hinzu\")\n",
    "    print(\"- OHE für *_cat, Impute/Scale für numerische, Impute für binär\")\n",
    "    print(\"- trainiert LogReg L2 und misst CV-AUC\")\n",
    "    print(\"- speichert:\")\n",
    "    print(f\"  • Modell: {models/'kagglepreset_logreg_l2.joblib'}\")\n",
    "    print(f\"  • Featureliste: {feat_path}\")\n",
    "    print(f\"  • Meta/Entscheidung: {reports/'kagglepreset_decision.json'}\")\n",
    "\n",
    "    print()\n",
    "    print(\"b) Was sagen die Ergebnisse?\")\n",
    "    print(f\"- AUC (CV={CV}, N={len(y):,}): {auc:.4f}\")\n",
    "    print(\"- Interpretation: Der Kaggle-Preset (calc raus + einfache FE + OHE) trägt.\")\n",
    "    print(\"- Die Datei selected_features_kagglepreset.csv ist jetzt eine schlanke Feature-Basis für weitere Modelle.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

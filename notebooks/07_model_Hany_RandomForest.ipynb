{
 "cells": [
  {
   "cell_type": "code",
   "id": "ecd19370de77ee70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T10:07:05.313020Z",
     "start_time": "2025-10-02T10:07:04.507297Z"
    }
   },
   "source": [
    "import os, sys, json, warnings, time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, brier_score_loss, precision_recall_curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "# ---------- Pfade und Konfiguration ---------->\n",
    "if \"__file__\" in globals():\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "else:\n",
    "    ROOT = Path.cwd() if Path.cwd().name not in (\"notebooks\",\"tools\",\"tests\") else Path.cwd().parent\n",
    "sys.path.insert(0, str(ROOT))\n",
    "from src.data_loader import load_and_save_data\n",
    "\n",
    "REPORTS_IN  = Path(os.getenv(\"REPORTS_IN\")  or (ROOT / \"reports\"))\n",
    "REPORTS_OUT = Path(os.getenv(\"REPORTS_OUT\") or (ROOT / \"reports_Hany/RandomForest\"))\n",
    "REPORTS_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SPEED = os.getenv(\"SPEED\", \"FAST\").upper().strip()\n",
    "def speed_cfg():\n",
    "    cfg = dict(CV=5, N_ITER_SEARCH=20)\n",
    "    if SPEED == \"FAST\":\n",
    "        cfg.update(CV=5, N_EST=200, EN_ITER_SEARCH=5)\n",
    "    elif SPEED == \"MEDIUM\":\n",
    "        cfg.update(CV=5, N_EST=1000, N_ITER_SEARCH=10)\n",
    "    elif SPEED == \"FULL\":\n",
    "        cfg.update(CV=5, N_EST=2000, N_ITER_SEARCH=20)\n",
    "    return cfg\n",
    "\n",
    "CFG        = speed_cfg()\n",
    "RND        = int(os.getenv(\"RND\", \"42\"))\n",
    "CV         = int(os.getenv(\"CV\", str(CFG[\"CV\"])))\n",
    "N_EST      = int(os.getenv(\"N_EST\", str(CFG[\"N_EST\"])))\n",
    "MEMBER     = os.getenv(\"MEMBER\", \"Hany\")\n",
    "\n",
    "print(f\"[SETUP] SPEED={SPEED} CV={CV} N_EST={N_EST} MODEL=RandomForest\")\n",
    "\n",
    "# Hilfsfunktionen zur Datenaufbereitung\n",
    "def split_cols(cols):\n",
    "    #Trenne Spalten in kategorische, binäre und numerische.\"\"\"\n",
    "    cat = [c for c in cols if str(c).endswith(\"_cat\")]\n",
    "    bin_ = [c for c in cols if str(c).endswith(\"_bin\")]\n",
    "    num  = [c for c in cols if c not in cat and c not in bin_ and c != \"target\"]\n",
    "    return cat, bin_, num\n",
    "\n",
    "def load_selected_feature_list():\n",
    "    #Lade die Liste der ausgewählten Features.\n",
    "    f = REPORTS_IN / \"features_selected.csv\"\n",
    "    if not f.exists():\n",
    "        raise FileNotFoundError(f\"Missing {f}. Run feature-gate first.\")\n",
    "    s = pd.read_csv(f)\n",
    "    if \"raw_feature\" not in s.columns:\n",
    "        raise ValueError(\"features_selected.csv must have column 'raw_feature'.\")\n",
    "    return s[\"raw_feature\"].astype(str).tolist()\n",
    "\n",
    "def fe_extras(X, selected):\n",
    "    #Erstelle zusätzliche Features.\n",
    "    X = X.copy()\n",
    "    if \"missing_count\" in selected:\n",
    "        X[\"missing_count\"] = X.isna().sum(axis=1)\n",
    "    if \"sum_all_bin\" in selected:\n",
    "        b = [c for c in X.columns if str(c).endswith(\"_bin\")]\n",
    "        X[\"sum_all_bin\"] = X[b].sum(axis=1)\n",
    "    return X\n",
    "\n",
    "def prep_for_model(X: pd.DataFrame, selected_cols):\n",
    "    #Preprocessor-Schritt für die OHE-Pipeline\n",
    "    keep = [c for c in selected_cols if c in X.columns]\n",
    "    missing = [c for c in selected_cols if c not in X.columns]\n",
    "    if missing: print(f\"[WARN] ignoring {len(missing)} missing selected feature(s).\")\n",
    "    X = X[keep].copy()\n",
    "\n",
    "    cat, bin_, num = split_cols(X.columns)\n",
    "\n",
    "    pre = ColumnTransformer([\n",
    "        (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")), (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))]), cat),\n",
    "        (\"bin\", SimpleImputer(strategy=\"most_frequent\"), bin_),\n",
    "        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num)\n",
    "    ], remainder=\"drop\")\n",
    "\n",
    "    return pre\n",
    "\n",
    "# Hilfsfunktionen für OOF und finales Training\n",
    "def oof_cv(model_name, X, y, preprocessor, model_params=None):\n",
    "    #Kreuzvalidierung.\n",
    "    skf = StratifiedKFold(n_splits=CV, shuffle=True, random_state=RND)\n",
    "    oof = np.zeros(len(y), dtype=float)\n",
    "\n",
    "    defaults = {\n",
    "        'n_estimators': N_EST,\n",
    "        'random_state': RND,\n",
    "        'n_jobs': -1,\n",
    "        'class_weight': 'balanced'\n",
    "    }\n",
    "    defaults.update(model_params or {})\n",
    "\n",
    "    clf = RandomForestClassifier(**defaults)\n",
    "    pipe = Pipeline([(\"pre\", preprocessor), (\"clf\", clf)])\n",
    "\n",
    "    for tr, va in skf.split(X, y):\n",
    "        Xtr, Xva = X.iloc[tr], X.iloc[va]; ytr, yva = y.iloc[tr], y.iloc[va]\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        oof[va] = pipe.predict_proba(Xva)[:,1]\n",
    "\n",
    "    pr  = average_precision_score(y, oof)\n",
    "    roc = roc_auc_score(y, oof)\n",
    "    brier = brier_score_loss(y, oof)\n",
    "    return dict(pr_auc=float(pr), roc_auc=float(roc), brier=float(brier), oof=oof)\n",
    "\n",
    "def fit_final(Xtr, ytr, Xte, yte, preprocessor, model_params=None):\n",
    "    defaults = {\n",
    "        'n_estimators': N_EST,\n",
    "        'random_state': RND,\n",
    "        'n_jobs': -1,\n",
    "        'class_weight': 'balanced'\n",
    "    }\n",
    "    defaults.update(model_params or {})\n",
    "\n",
    "    clf = RandomForestClassifier(**defaults)\n",
    "    pipe = Pipeline([(\"pre\", preprocessor), (\"clf\", clf)])\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    fit_time_s = time.perf_counter() - t0\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    proba = pipe.predict_proba(Xte)[:,1]\n",
    "    pred_ms_per_1k = 1000 * (time.perf_counter() - t1) / (len(Xte)/1000)\n",
    "\n",
    "    try:\n",
    "        feature_names = pipe.named_steps['pre'].get_feature_names_out()\n",
    "        fi = pd.Series(pipe.named_steps['clf'].feature_importances_, index=feature_names, name=\"gain\").sort_values(ascending=False)\n",
    "    except:\n",
    "        fi = None\n",
    "\n",
    "    meta = {\n",
    "        \"encoder\": \"OHE\",\n",
    "        \"n_trees\": defaults['n_estimators'],\n",
    "        \"fit_time_s\": float(fit_time_s),\n",
    "        \"predict_time_ms_per_1k\": float(pred_ms_per_1k),\n",
    "        \"params\": model_params\n",
    "    }\n",
    "    hold = dict(pr_auc=float(average_precision_score(yte, proba)), roc_auc=float(roc_auc_score(yte, proba)), brier=float(brier_score_loss(yte, proba)))\n",
    "\n",
    "    return proba, hold, fi, meta\n",
    "\n",
    "#Berichtsfunktionen\n",
    "def save_pr_curve(y_true, proba, out_path):\n",
    "    prec, rec, _ = precision_recall_curve(y_true, proba); ap = average_precision_score(y_true, proba)\n",
    "    plt.figure(figsize=(7,5)); plt.plot(rec, prec, label=f'AP={ap:.4f}')\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall')\n",
    "    plt.xlim([0,1]); plt.ylim([0,1]); plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def save_calibration(y_true, proba, out_path):\n",
    "    prob_true, prob_pred = calibration_curve(y_true, proba, n_bins=20, strategy=\"quantile\")\n",
    "    plt.figure(figsize=(6,6)); plt.plot([0,1],[0,1],'--',label='Perfect')\n",
    "    plt.plot(prob_pred, prob_true, marker='o', label='Model')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Observed'); plt.title('Calibration')\n",
    "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def save_top20_importance(fi: pd.Series, out_path):\n",
    "    if fi is None or fi.empty: return\n",
    "    top = fi.head(20).iloc[::-1]\n",
    "    plt.figure(figsize=(8,6)); plt.barh(top.index, top.values)\n",
    "    plt.xlabel('Gain'); plt.title('Top-20 Feature Importance')\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def log_summary(row, filename=\"team_model_summary.csv\"):\n",
    "    out_csv = REPORTS_OUT/filename\n",
    "    pd.DataFrame([row]).to_csv(out_csv, mode=\"a\", index=False, header=not out_csv.exists())\n",
    "\n",
    "def plot_model_comparison(results_list, out_path):\n",
    "    # Vergleicht die PR-AUC, ROC-AUC und den Brier-Score der Modelle\n",
    "    df_results = pd.DataFrame(results_list)\n",
    "    df_results.set_index(\"model_name\", inplace=True)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    df_results['hold_ap'].plot(kind='barh', ax=axes[0], title='PR-AUC')\n",
    "    df_results['hold_auc'].plot(kind='barh', ax=axes[1], title='ROC-AUC')\n",
    "    df_results['hold_brier'].plot(kind='barh', ax=axes[2], title='Brier-Score')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), rotation=0, ha='right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Modellvergleichs-Plot gespeichert: {out_path}\")\n",
    "\n",
    "def plot_prediction_distributions_kde(predictions, y_true, out_path):\n",
    "    all_data = []\n",
    "    for model_name, proba in predictions.items():\n",
    "        df_plot = pd.DataFrame({'proba': proba, 'model': model_name, 'y_true': y_true})\n",
    "        all_data.append(df_plot)\n",
    "\n",
    "    df_combined = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    plt.figure(figsize=(14, 9))\n",
    "    sns.kdeplot(\n",
    "        data=df_combined,\n",
    "        x='proba',\n",
    "        hue='y_true',\n",
    "        fill=True,\n",
    "        alpha=0.6,\n",
    "        common_norm=False,\n",
    "        legend=True\n",
    "    )\n",
    "    plt.title('Verteilung der Vorhersagewahrscheinlichkeiten nach Modell und wahrer Klasse')\n",
    "    plt.xlabel('Vorhergesagte Wahrscheinlichkeit')\n",
    "    plt.ylabel('Dichte')\n",
    "    plt.legend(title='Modell | Klasse')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Verteilungs-Plot (KDE) wurde gespeichert: {out_path}\")\n",
    "\n",
    "\n",
    "def plot_pr_curve_all(predictions, y_true, out_path):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for model_name, proba in predictions.items():\n",
    "        prec, rec, _ = precision_recall_curve(y_true, proba)\n",
    "        ap_score = average_precision_score(y_true, proba)\n",
    "        plt.plot(rec, prec, label=f'{model_name} (AP={ap_score:.4f})')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Vergleich der Precision-Recall-Kurven')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Precision-Recall-Kurven-Vergleichsplot wurde gespeichert: {out_path}\")\n",
    "\n",
    "# Daten laden und aufteilen\n",
    "split_p = REPORTS_IN / \"split_indices.json\"\n",
    "feats_p = REPORTS_IN / \"features_selected.csv\"\n",
    "assert split_p.exists() and feats_p.exists(), \"Missing split and/or features files in reports.\"\n",
    "\n",
    "split = json.loads(split_p.read_text())\n",
    "selected = load_selected_feature_list()\n",
    "\n",
    "df = load_and_save_data().replace(-1, np.nan)\n",
    "X_tr_all = df.loc[split[\"train\"]].drop(columns=[\"target\"])\n",
    "y_tr     = df.loc[split[\"train\"], \"target\"].astype(int)\n",
    "X_te_all = df.loc[split[\"test\"]].drop(columns=[\"target\"])\n",
    "y_te     = df.loc[split[\"test\"], \"target\"].astype(int)\n",
    "\n",
    "X_tr_fe = fe_extras(X_tr_all.copy(), selected)\n",
    "X_te_fe = fe_extras(X_te_all.copy(), selected)\n",
    "\n",
    "selected_fe = list(set(selected + [\"missing_count\", \"sum_all_bin\"]))\n",
    "selected_fe = [c for c in selected_fe if c in X_tr_fe.columns]\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SETUP] SPEED=FAST CV=5 N_EST=200 MODEL=RandomForest\n",
      "Loading dataset from in-memory cache.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "294f6a02c1e7ece2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:50:33.864491Z",
     "start_time": "2025-10-02T08:47:43.577245Z"
    }
   },
   "source": [
    "print(f\"\\n[EXPERIMENT 1] Baseline RandomForest with default params\")\n",
    "\n",
    "preprocessor_ohe = prep_for_model(X_tr_fe, selected_fe)\n",
    "base_params = {}\n",
    "\n",
    "res_base = oof_cv(\"rf_baseline\", X_tr_fe, y_tr, preprocessor_ohe, model_params=base_params)\n",
    "proba_base, hold_base, fi_base, meta_base = fit_final(X_tr_fe, y_tr, X_te_fe, y_te, preprocessor_ohe, model_params=base_params)\n",
    "\n",
    "report_name_base = \"rf_baseline\"\n",
    "pd.DataFrame({\"oof\": res_base[\"oof\"]}).to_csv(REPORTS_OUT/f\"oof_{report_name_base}.csv\", index=False)\n",
    "\n",
    "pd.DataFrame({\"proba\": proba_base, \"y_true\": y_te.values}).to_csv(REPORTS_OUT/f\"holdout_preds_{report_name_base}.csv\", index=False)\n",
    "\n",
    "if fi_base is not None and not fi_base.empty:\n",
    "    fi_base.reset_index().rename(columns={\"index\":\"feature\"}).to_csv(REPORTS_OUT/f\"fi_gain_{report_name_base}.csv\", index=False)\n",
    "\n",
    "save_pr_curve(y_te.values, proba_base, REPORTS_OUT/f\"plot_pr_{report_name_base}.png\")\n",
    "\n",
    "save_calibration(y_te.values, proba_base, REPORTS_OUT/f\"plot_calibration_{report_name_base}.png\")\n",
    "\n",
    "if fi_base is not None: save_top20_importance(fi_base, REPORTS_OUT/f\"plot_fi_top20_{report_name_base}.png\")\n",
    "\n",
    "row_base = {\n",
    "    \"member\": MEMBER, \"model_name\": \"RF_Baseline\", \"encoder\": \"OHE\",\n",
    "    \"split_path\": str(split_p), \"feature_recipe\": \"selected\",\n",
    "    \"seed\": RND, \"cv_folds\": CV, \"hold_auc\": hold_base[\"roc_auc\"], \"hold_ap\": hold_base[\"pr_auc\"],\n",
    "    \"hold_brier\": hold_base[\"brier\"], \"cv_auc_mean\": res_base[\"roc_auc\"], \"cv_ap_mean\": res_base[\"pr_auc\"],\n",
    "    \"early_stopping\": False, \"best_iteration\": None,\n",
    "    \"n_trees\": N_EST, \"fit_time_s\": meta_base[\"fit_time_s\"],\n",
    "    \"predict_time_ms_per_1k\": meta_base[\"predict_time_ms_per_1k\"], \"params_json\": json.dumps(base_params)\n",
    "}\n",
    "log_summary(row_base)\n",
    "print(f\"\\n[BASELINES] PR-AUC={res_base['pr_auc']:.5f}  ROC-AUC={res_base['roc_auc']:.5f}  Brier={res_base['brier']:.5f}\")\n",
    "print(f\"[HOLDOUT] PR-AUC={hold_base['pr_auc']:.5f}  ROC-AUC={hold_base['roc_auc']:.5f}  Brier={hold_base['brier']:.5f}\")\n",
    "print(f\"Reports saved to: {REPORTS_OUT}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EXPERIMENT 1] Baseline RandomForest with default params\n",
      "\n",
      "[BASELINES] PR-AUC=0.04908  ROC-AUC=0.58584  Brier=0.03541\n",
      "[HOLDOUT] PR-AUC=0.05352  ROC-AUC=0.60310  Brier=0.03526\n",
      "Reports saved to: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\\RandomForest\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4ffa36590a8c205b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T09:37:46.153525Z",
     "start_time": "2025-10-02T08:50:37.977885Z"
    }
   },
   "source": [
    "print(f\"\\n[EXPERIMENT 2] Hyperparameter Tuning with Randomized Search (OHE)\")\n",
    "\n",
    "param_grid_ohe = {\n",
    "    'clf__n_estimators': [int(N_EST*0.5), N_EST, int(N_EST*1.5)],\n",
    "    'clf__max_depth': [10, 20, None],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "clf_ohe = RandomForestClassifier(random_state=RND, n_jobs=-1)\n",
    "pipe_ohe = Pipeline([(\"pre\", preprocessor_ohe), (\"clf\", clf_ohe)])\n",
    "\n",
    "random_search_ohe = RandomizedSearchCV(\n",
    "    pipe_ohe,\n",
    "    param_distributions=param_grid_ohe,\n",
    "    n_iter=20,\n",
    "    cv=CV,\n",
    "    scoring='average_precision',\n",
    "    random_state=RND,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search_ohe.fit(X_tr_fe, y_tr)\n",
    "\n",
    "best_params_ohe = {k.replace('clf__', ''): v for k, v in random_search_ohe.best_params_.items()}\n",
    "best_score_ohe = random_search_ohe.best_score_\n",
    "\n",
    "print(f\"Best parameters found: {best_params_ohe}\")\n",
    "print(f\"Best cross-validation PR-AUC: {best_score_ohe:.4f}\")\n",
    "\n",
    "print(\"[INFO] Training final model with best parameters...\")\n",
    "\n",
    "proba_tuned_ohe, hold_tuned_ohe, fi_tuned_ohe, meta_tuned_ohe = fit_final(X_tr_fe, y_tr, X_te_fe, y_te, preprocessor_ohe, model_params=best_params_ohe)\n",
    "\n",
    "\n",
    "report_name_tuned_ohe = \"rf_tuned_ohe\"\n",
    "pd.DataFrame({\"proba\": proba_tuned_ohe, \"y_true\": y_te.values}).to_csv(REPORTS_OUT/f\"holdout_preds_{report_name_tuned_ohe}.csv\", index=False)\n",
    "if fi_tuned_ohe is not None and not fi_tuned_ohe.empty:\n",
    "    fi_tuned_ohe.reset_index().rename(columns={\"index\":\"feature\"}).to_csv(REPORTS_OUT/f\"fi_gain_{report_name_tuned_ohe}.csv\", index=False)\n",
    "save_pr_curve(y_te.values, proba_tuned_ohe, REPORTS_OUT/f\"plot_pr_{report_name_tuned_ohe}.png\")\n",
    "save_calibration(y_te.values, proba_tuned_ohe, REPORTS_OUT/f\"plot_calibration_{report_name_tuned_ohe}.png\")\n",
    "if fi_tuned_ohe is not None: save_top20_importance(fi_tuned_ohe, REPORTS_OUT/f\"plot_fi_top20_{report_name_tuned_ohe}.png\")\n",
    "\n",
    "row_tuned_ohe = {\n",
    "    \"member\": MEMBER, \"model_name\": \"RF_Tuned_OHE\", \"encoder\": meta_tuned_ohe[\"encoder\"],\n",
    "    \"split_path\": str(split_p), \"feature_recipe\": \"selected\",\n",
    "    \"seed\": RND, \"cv_folds\": CV, \"hold_auc\": hold_tuned_ohe[\"roc_auc\"], \"hold_ap\": hold_tuned_ohe[\"pr_auc\"],\n",
    "    \"hold_brier\": hold_tuned_ohe[\"brier\"], \"cv_auc_mean\": random_search_ohe.cv_results_['mean_test_score'].max(), \"cv_ap_mean\": best_score_ohe,\n",
    "    \"early_stopping\": False, \"best_iteration\": None,\n",
    "    \"n_trees\": best_params_ohe.get('n_estimators', N_EST), \"fit_time_s\": meta_tuned_ohe[\"fit_time_s\"],\n",
    "    \"predict_time_ms_per_1k\": meta_tuned_ohe[\"predict_time_ms_per_1k\"], \"params_json\": json.dumps(best_params_ohe)\n",
    "}\n",
    "log_summary(row_tuned_ohe)\n",
    "print(f\"\\n[HOLDOUT] (Tuned, OHE) PR-AUC={hold_tuned_ohe['pr_auc']:.5f}  ROC-AUC={hold_tuned_ohe['roc_auc']:.5f}  Brier={hold_tuned_ohe['brier']:.5f}\")\n",
    "print(f\"Reports saved to: {REPORTS_OUT}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EXPERIMENT 2] Hyperparameter Tuning with Randomized Search (OHE)\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters found: {'n_estimators': 300, 'min_samples_leaf': 4, 'max_depth': 10, 'class_weight': None}\n",
      "Best cross-validation PR-AUC: 0.0642\n",
      "[INFO] Training final model with best parameters...\n",
      "\n",
      "[HOLDOUT] (Tuned, OHE) PR-AUC=0.06872  ROC-AUC=0.63874  Brier=0.03491\n",
      "Reports saved to: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\\RandomForest\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T10:05:54.420339Z",
     "start_time": "2025-10-02T09:37:51.091609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\\\n[EXPERIMENT 3] RandomForest mit Target Encoding\")\n",
    "\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, smoothing=10.0):\n",
    "        self.smoothing = smoothing\n",
    "        self.mappings = {}\n",
    "        self.global_mean = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_temp = X.copy()\n",
    "        y_temp = y.copy()\n",
    "        X_temp['target'] = y_temp\n",
    "        self.global_mean = y_temp.mean()\n",
    "\n",
    "        for col in X.columns:\n",
    "            agg = X_temp.groupby(col)['target'].agg(['count', 'mean'])\n",
    "            counts = agg['count']\n",
    "            means = agg['mean']\n",
    "            smooth = (counts * means + self.smoothing * self.global_mean) / (counts + self.smoothing)\n",
    "            self.mappings[col] = smooth\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_new = X.copy()\n",
    "        for col, mapping in self.mappings.items():\n",
    "            X_new[col] = X_new[col].map(mapping).fillna(self.global_mean)\n",
    "        return X_new\n",
    "\n",
    "# Datenvorverearveitung\n",
    "cat_cols, _, _ = split_cols(X_tr_fe.columns)\n",
    "X_tr_te = X_tr_fe.copy()\n",
    "X_te_te = X_te_fe.copy()\n",
    "\n",
    "target_encoder = TargetEncoder()\n",
    "target_encoder.fit(X_tr_te[cat_cols], y_tr)\n",
    "\n",
    "X_tr_te[cat_cols] = target_encoder.transform(X_tr_te[cat_cols])\n",
    "X_te_te[cat_cols] = target_encoder.transform(X_te_te[cat_cols])\n",
    "\n",
    "print(\"Target Encoding wurde auf die Daten angewendet.\")\n",
    "\n",
    "# Pipeline und Hyperparameter-Suche anpassen ----------\n",
    "preprocessor_te = SimpleImputer(strategy='median')\n",
    "pipe_te = Pipeline([\n",
    "    (\"pre\", preprocessor_te),\n",
    "    (\"clf\", RandomForestClassifier(random_state=RND, n_jobs=-1))\n",
    "])\n",
    "\n",
    "param_grid_te = {\n",
    "    'clf__n_estimators': [int(N_EST*0.5), N_EST, int(N_EST*1.5)],\n",
    "    'clf__max_depth': [10, 20, None],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "random_search_te = RandomizedSearchCV(\n",
    "    pipe_te,\n",
    "    param_distributions=param_grid_te,\n",
    "    n_iter=20,\n",
    "    cv=CV,\n",
    "    scoring='average_precision',\n",
    "    random_state=RND,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\\\nStarte Hyperparameter-Suche für Target-Encoded Modell\")\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "random_search_te.fit(X_tr_te, y_tr)\n",
    "fit_time_te = time.perf_counter() - t0\n",
    "best_params_te = {k.replace('clf__', ''): v for k, v in random_search_te.best_params_.items()}\n",
    "best_score_te = random_search_te.best_score_\n",
    "\n",
    "print(f\"\\nBeste Parameter (Target Encoding): {best_params_te}\")\n",
    "print(f\"Bester Cross-Validation PR-AUC (Target Encoding): {best_score_te:.4f}\")\n",
    "\n",
    "# Finale Auswertung und Ergebnisse\n",
    "final_model_te = random_search_te.best_estimator_\n",
    "t1 = time.perf_counter()\n",
    "proba_te = final_model_te.predict_proba(X_te_te)[:, 1]\n",
    "pred_time_te = 1000 * (time.perf_counter() - t1) / (len(X_te_te)/1000)\n",
    "\n",
    "hold_te = {\n",
    "    \"pr_auc\": average_precision_score(y_te, proba_te),\n",
    "    \"roc_auc\": roc_auc_score(y_te, proba_te),\n",
    "    \"brier\": brier_score_loss(y_te, proba_te),\n",
    "}\n",
    "print(f\"\\n[HOLDOUT] (Tuned, Target Encoding) PR-AUC={hold_te['pr_auc']:.5f}  ROC-AUC={hold_te['roc_auc']:.5f}  Brier={hold_te['brier']:.5f}\")\n",
    "\n",
    "# Reporting, Plots und Logging\n",
    "try:\n",
    "    fi_te = pd.Series(final_model_te.named_steps['clf'].feature_importances_, index=X_tr_te.columns, name=\"gain\").sort_values(ascending=False)\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] Feature Importance konnte nicht extrahiert werden: {e}\")\n",
    "    fi_te = None\n",
    "\n",
    "report_name_te = \"rf_tuned_targetenc\"\n",
    "pd.DataFrame({\"proba\": proba_te, \"y_true\": y_te.values}).to_csv(REPORTS_OUT/f\"holdout_preds_{report_name_te}.csv\", index=False)\n",
    "if fi_te is not None and not fi_te.empty:\n",
    "    fi_te.reset_index().rename(columns={\"index\":\"feature\"}).to_csv(REPORTS_OUT/f\"fi_gain_{report_name_te}.csv\", index=False)\n",
    "save_pr_curve(y_te.values, proba_te, REPORTS_OUT/f\"plot_pr_{report_name_te}.png\")\n",
    "save_calibration(y_te.values, proba_te, REPORTS_OUT/f\"plot_calibration_{report_name_te}.png\")\n",
    "if fi_te is not None:\n",
    "    save_top20_importance(fi_te, REPORTS_OUT/f\"plot_fi_top20_{report_name_te}.png\")\n",
    "\n",
    "# Da RandomizedSearchCV keine CV-Metriken für ROC-AUC speichert - AP-Score als Platzhalter\n",
    "cv_results_te = {\"pr_auc\": best_score_te, \"roc_auc\": best_score_te}\n",
    "row_te = {\n",
    "    \"member\": MEMBER, \"model_name\": \"RF_Tuned_TargetEnc\", \"encoder\": \"TargetEnc\",\n",
    "    \"split_path\": str(split_p), \"feature_recipe\": \"selected\",\n",
    "    \"seed\": RND, \"cv_folds\": CV, \"hold_auc\": hold_te[\"roc_auc\"], \"hold_ap\": hold_te[\"pr_auc\"],\n",
    "    \"hold_brier\": hold_te[\"brier\"], \"cv_auc_mean\": best_score_te, \"cv_ap_mean\": best_score_te,\n",
    "    \"early_stopping\": False, \"best_iteration\": None,\n",
    "    \"n_trees\": best_params_te.get('n_estimators', N_EST),\n",
    "    \"fit_time_s\": fit_time_te,\n",
    "    \"predict_time_ms_per_1k\": pred_time_te,\n",
    "    \"params_json\": json.dumps(best_params_te)\n",
    "}\n",
    "log_summary(row_te)\n",
    "print(\"Ergebnisse wurden erfolgreich in die Zusammenfassungs-CSV geloggt.\")\n",
    "print(f\"Reports saved to: {REPORTS_OUT}\")"
   ],
   "id": "e09da94c5e51d000",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n[EXPERIMENT 3] RandomForest mit Target Encoding\n",
      "Target Encoding wurde auf die Daten angewendet.\n",
      "\\nStarte Hyperparameter-Suche für Target-Encoded Modell\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "Beste Parameter (Target Encoding): {'n_estimators': 300, 'min_samples_leaf': 4, 'max_depth': 10, 'class_weight': None}\n",
      "Bester Cross-Validation PR-AUC (Target Encoding): 0.0650\n",
      "\n",
      "[HOLDOUT] (Tuned, Target Encoding) PR-AUC=0.06645  ROC-AUC=0.63437  Brier=0.03490\n",
      "Ergebnisse wurden erfolgreich in die Zusammenfassungs-CSV geloggt.\n",
      "Reports saved to: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\\RandomForest\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T10:07:14.681284Z",
     "start_time": "2025-10-02T10:07:13.062875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n--- Zusätzliche Analysen und Visualisierungen ---\")\n",
    "\n",
    "try:\n",
    "    # Sammeln der Hold-out-Ergebnisse für den Vergleichsplot\n",
    "    all_holdout_results = [\n",
    "        {\"model_name\": \"RF_Baseline\", \"hold_ap\": hold_base[\"pr_auc\"], \"hold_auc\": hold_base[\"roc_auc\"], \"hold_brier\": hold_base[\"brier\"]},\n",
    "        {\"model_name\": \"RF_Tuned_OHE\", \"hold_ap\": hold_tuned_ohe[\"pr_auc\"], \"hold_auc\": hold_tuned_ohe[\"roc_auc\"], \"hold_brier\": hold_tuned_ohe[\"brier\"]},\n",
    "        {\"model_name\": \"RF_Tuned_TargetEnc\", \"hold_ap\": hold_te[\"pr_auc\"], \"hold_auc\": hold_te[\"roc_auc\"], \"hold_brier\": hold_te[\"brier\"]}\n",
    "    ]\n",
    "\n",
    "    all_predictions = {\n",
    "        \"RF_Baseline\": proba_base,\n",
    "        \"RF_Tuned_OHE\": proba_tuned_ohe,\n",
    "        \"RF_Tuned_TargetEnc\": proba_te\n",
    "    }\n",
    "    # Plot 1: KDE-Plot der Vorhersage-Verteilungen\n",
    "    plot_prediction_distributions_kde(all_predictions, y_te, REPORTS_OUT / \"plot_proba_distribution_comparison.png\")\n",
    "\n",
    "    # Plot 2: Vergleich der Precision-Recall-Kurven\n",
    "    plot_pr_curve_all(all_predictions, y_te, REPORTS_OUT / \"plot_pr_curve_comparison.png\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Fehler: Eine der Variablen ist nicht definiert. Stellen Sie sicher, dass alle vorherigen Schritte zur Modellauswertung erfolgreich ausgeführt wurden. Details: {e}\")\n",
    "\n",
    "print(f\"Reports saved to: {REPORTS_OUT}\")\n"
   ],
   "id": "935de6f9160730c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Zusätzliche Analysen und Visualisierungen ---\n",
      "[INFO] Verteilungs-Plot (KDE) wurde gespeichert: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\\RandomForest\\plot_proba_distribution_comparison.png\n",
      "[INFO] Precision-Recall-Kurven-Vergleichsplot wurde gespeichert: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\\RandomForest\\plot_pr_curve_comparison.png\n",
      "Reports saved to: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\\RandomForest\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "60bed0ef9abd7d6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (porto_seguro_env)",
   "language": "python",
   "name": "porto_seguro_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

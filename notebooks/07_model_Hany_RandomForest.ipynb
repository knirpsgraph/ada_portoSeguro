{
 "cells": [
  {
   "cell_type": "code",
   "id": "ecd19370de77ee70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T19:45:52.871555Z",
     "start_time": "2025-09-29T19:45:52.109506Z"
    }
   },
   "source": [
    "import os, sys, json, warnings, time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, brier_score_loss, precision_recall_curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# ---------- Pfade ----------\n",
    "if \"__file__\" in globals():\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "else:\n",
    "    ROOT = Path.cwd() if Path.cwd().name not in (\"notebooks\",\"tools\",\"tests\") else Path.cwd().parent\n",
    "sys.path.insert(0, str(ROOT))\n",
    "from src.data_loader import load_and_save_data\n",
    "\n",
    "REPORTS_IN  = Path(os.getenv(\"REPORTS_IN\")  or (ROOT / \"reports\"))\n",
    "REPORTS_OUT = Path(os.getenv(\"REPORTS_OUT\") or (ROOT / \"reports_Hany\"))\n",
    "REPORTS_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Konfiguration ----------\n",
    "SPEED = os.getenv(\"SPEED\", \"MEDIUM\").upper().strip()\n",
    "def speed_cfg():\n",
    "    cfg = dict(CV=5, N_EST=100)\n",
    "    if SPEED == \"FAST\":\n",
    "        cfg.update(CV=3, N_EST=50)\n",
    "    elif SPEED == \"MEDIUM\":\n",
    "        cfg.update(CV=5, N_EST=100)\n",
    "    elif SPEED == \"FULL\":\n",
    "        cfg.update(CV=5, N_EST=200)\n",
    "    return cfg\n",
    "\n",
    "CFG        = speed_cfg()\n",
    "RND        = int(os.getenv(\"RND\", \"42\"))\n",
    "CV         = int(os.getenv(\"CV\", str(CFG[\"CV\"])))\n",
    "N_EST      = int(os.getenv(\"N_EST\", str(CFG[\"N_EST\"])))\n",
    "MEMBER     = os.getenv(\"MEMBER\", \"Hany\")\n",
    "\n",
    "# ---------- Hilfsfunktionen zur Datenaufbereitung ----------\n",
    "def split_cols(cols):\n",
    "    cat = [c for c in cols if str(c).endswith(\"_cat\")]\n",
    "    bin_ = [c for c in cols if str(c).endswith(\"_bin\")]\n",
    "    num  = [c for c in cols if c not in cat and c not in bin_ and c != \"target\"]\n",
    "    return cat, bin_, num\n",
    "\n",
    "def load_selected_feature_list():\n",
    "    f = REPORTS_IN / \"features_selected.csv\"\n",
    "    if not f.exists():\n",
    "        raise FileNotFoundError(f\"Missing {f}. Run feature-gate first.\")\n",
    "    s = pd.read_csv(f)\n",
    "    if \"raw_feature\" not in s.columns:\n",
    "        raise ValueError(\"features_selected.csv must have column 'raw_feature'.\")\n",
    "    return s[\"raw_feature\"].astype(str).tolist()\n",
    "\n",
    "def fe_extras(X, selected):\n",
    "    X = X.copy()\n",
    "    if \"missing_count\" in selected:\n",
    "        X[\"missing_count\"] = X.isna().sum(axis=1)\n",
    "    if \"sum_all_bin\" in selected:\n",
    "        b = [c for c in X.columns if str(c).endswith(\"_bin\")]\n",
    "        X[\"sum_all_bin\"] = X[b].sum(axis=1)\n",
    "    return X\n",
    "\n",
    "def prep_for_model(X: pd.DataFrame, selected_cols):\n",
    "    keep = [c for c in selected_cols if c in X.columns]\n",
    "    missing = [c for c in selected_cols if c not in X.columns]\n",
    "    if missing: print(f\"[WARN] ignoring {len(missing)} missing selected feature(s).\")\n",
    "    X = X[keep].copy()\n",
    "\n",
    "    cat, bin_, num = split_cols(X.columns)\n",
    "\n",
    "    pre = ColumnTransformer([\n",
    "        (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")), (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))]), cat),\n",
    "        (\"bin\", SimpleImputer(strategy=\"most_frequent\"), bin_),\n",
    "        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num)\n",
    "    ], remainder=\"drop\")\n",
    "\n",
    "    return pre\n",
    "\n",
    "def oof_cv(model_name, X, y, selected, model_params=None):\n",
    "    skf = StratifiedKFold(n_splits=CV, shuffle=True, random_state=RND)\n",
    "    oof = np.zeros(len(y), dtype=float)\n",
    "    pre = prep_for_model(X, selected)\n",
    "\n",
    "    defaults = {\n",
    "        'n_estimators': N_EST,\n",
    "        'random_state': RND,\n",
    "        'n_jobs': -1,\n",
    "        'class_weight': 'balanced'\n",
    "    }\n",
    "    defaults.update(model_params or {})\n",
    "\n",
    "    clf = RandomForestClassifier(**defaults)\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)])\n",
    "\n",
    "    for tr, va in skf.split(X, y):\n",
    "        Xtr, Xva = X.iloc[tr], X.iloc[va]; ytr, yva = y.iloc[tr], y.iloc[va]\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        oof[va] = pipe.predict_proba(Xva)[:,1]\n",
    "\n",
    "    pr  = average_precision_score(y, oof)\n",
    "    roc = roc_auc_score(y, oof)\n",
    "    brier = brier_score_loss(y, oof)\n",
    "    return dict(pr_auc=float(pr), roc_auc=float(roc), brier=float(brier), oof=oof)\n",
    "\n",
    "def fit_final(Xtr, ytr, Xte, yte, selected_cols, model_params=None):\n",
    "    pre = prep_for_model(Xtr, selected_cols)\n",
    "\n",
    "    defaults = {\n",
    "        'n_estimators': N_EST,\n",
    "        'random_state': RND,\n",
    "        'n_jobs': -1,\n",
    "        'class_weight': 'balanced'\n",
    "    }\n",
    "    defaults.update(model_params or {})\n",
    "\n",
    "    clf = RandomForestClassifier(**defaults)\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)])\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    fit_time_s = time.perf_counter() - t0\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    proba = pipe.predict_proba(Xte)[:,1]\n",
    "    pred_ms_per_1k = 1000 * (time.perf_counter() - t1) / (len(Xte)/1000)\n",
    "\n",
    "    try:\n",
    "        feature_names = pipe.named_steps['pre'].get_feature_names_out()\n",
    "        fi = pd.Series(pipe.named_steps['clf'].feature_importances_, index=feature_names, name=\"gain\").sort_values(ascending=False)\n",
    "    except:\n",
    "        fi = None\n",
    "\n",
    "    meta = {\n",
    "        \"encoder\": \"OHE\",\n",
    "        \"n_trees\": defaults['n_estimators'],\n",
    "        \"fit_time_s\": float(fit_time_s),\n",
    "        \"predict_time_ms_per_1k\": float(pred_ms_per_1k),\n",
    "        \"params\": model_params\n",
    "    }\n",
    "    hold = dict(pr_auc=float(average_precision_score(yte, proba)), roc_auc=float(roc_auc_score(yte, proba)), brier=float(brier_score_loss(yte, proba)))\n",
    "\n",
    "    return proba, hold, fi, meta\n",
    "\n",
    "# ---------- Berichtsfunktionen ----------\n",
    "def save_pr_curve(y_true, proba, out_path):\n",
    "    prec, rec, _ = precision_recall_curve(y_true, proba); ap = average_precision_score(y_true, proba)\n",
    "    plt.figure(figsize=(7,5)); plt.plot(rec, prec, label=f'AP={ap:.4f}')\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall')\n",
    "    plt.xlim([0,1]); plt.ylim([0,1]); plt.grid(True, alpha=0.3); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def save_calibration(y_true, proba, out_path):\n",
    "    prob_true, prob_pred = calibration_curve(y_true, proba, n_bins=20, strategy=\"quantile\")\n",
    "    plt.figure(figsize=(6,6)); plt.plot([0,1],[0,1],'--',label='Perfect')\n",
    "    plt.plot(prob_pred, prob_true, marker='o', label='Model')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Observed'); plt.title('Calibration')\n",
    "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def save_top20_importance(fi: pd.Series, out_path):\n",
    "    if fi is None or fi.empty: return\n",
    "    top = fi.head(20).iloc[::-1]\n",
    "    plt.figure(figsize=(8,6)); plt.barh(top.index, top.values)\n",
    "    plt.xlabel('Gain'); plt.title('Top-20 Feature Importance')\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def log_summary(row, filename=\"team_model_summary.csv\"):\n",
    "    out_csv = REPORTS_OUT/filename\n",
    "    pd.DataFrame([row]).to_csv(out_csv, mode=\"a\", index=False, header=not out_csv.exists())\n",
    "\n",
    "# Daten laden und aufteilen\n",
    "print(f\"[SETUP] SPEED={SPEED} CV={CV} N_EST={N_EST} MODEL=RandomForest\")\n",
    "\n",
    "split_p = REPORTS_IN / \"split_indices.json\"\n",
    "feats_p = REPORTS_IN / \"features_selected.csv\"\n",
    "assert split_p.exists() and feats_p.exists(), \"Missing split and/or features files in reports.\"\n",
    "\n",
    "split = json.loads(split_p.read_text())\n",
    "selected = load_selected_feature_list()\n",
    "\n",
    "df = load_and_save_data().replace(-1, np.nan)\n",
    "X_tr_all = df.loc[split[\"train\"]].drop(columns=[\"target\"])\n",
    "y_tr     = df.loc[split[\"train\"], \"target\"].astype(int)\n",
    "X_te_all = df.loc[split[\"test\"]].drop(columns=[\"target\"])\n",
    "y_te     = df.loc[split[\"test\"], \"target\"].astype(int)\n",
    "\n",
    "# Erstellen der neuen Features auf den DataFrames\n",
    "X_tr_fe = fe_extras(X_tr_all.copy(), selected)\n",
    "X_te_fe = fe_extras(X_te_all.copy(), selected)\n",
    "\n",
    "# Update der Featureliste, um die neuen Features einzuschliessen\n",
    "selected_fe = list(set(selected + [\"missing_count\", \"sum_all_bin\"]))\n",
    "selected_fe = [c for c in selected_fe if c in X_tr_fe.columns]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SETUP] SPEED=MEDIUM CV=5 N_EST=100 MODEL=RandomForest\n",
      "Loading dataset from in-memory cache.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "294f6a02c1e7ece2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T19:52:47.933706Z",
     "start_time": "2025-09-29T19:51:10.466504Z"
    }
   },
   "source": [
    "print(f\"\\n[EXPERIMENT 1] Baseline RandomForest with default params\")\n",
    "\n",
    "base_params = {}\n",
    "res = oof_cv(\"rf_baseline\", X_tr_fe, y_tr, selected_fe, model_params=base_params)\n",
    "proba, hold, fi, meta = fit_final(X_tr_fe, y_tr, X_te_fe, y_te, selected_fe, model_params=base_params)\n",
    "\n",
    "report_name = \"rf_baseline\"\n",
    "pd.DataFrame({\"oof\": res[\"oof\"]}).to_csv(REPORTS_OUT/f\"oof_{report_name}.csv\", index=False)\n",
    "pd.DataFrame({\"proba\": proba, \"y_true\": y_te.values}).to_csv(REPORTS_OUT/f\"holdout_preds_{report_name}.csv\", index=False)\n",
    "if fi is not None and not fi.empty:\n",
    "    fi.reset_index().rename(columns={\"index\":\"feature\"}).to_csv(REPORTS_OUT/f\"fi_gain_{report_name}.csv\", index=False)\n",
    "save_pr_curve(y_te.values, proba, REPORTS_OUT/f\"plot_pr_{report_name}.png\")\n",
    "save_calibration(y_te.values, proba, REPORTS_OUT/f\"plot_calibration_{report_name}.png\")\n",
    "if fi is not None: save_top20_importance(fi, REPORTS_OUT/f\"plot_fi_top20_{report_name}.png\")\n",
    "\n",
    "row = {\n",
    "    \"member\": MEMBER, \"model_name\": \"RF_Baseline\", \"encoder\": \"OHE\",\n",
    "    \"split_path\": str(split_p), \"feature_recipe\": \"selected\",\n",
    "    \"seed\": RND, \"cv_folds\": CV, \"hold_auc\": hold[\"roc_auc\"], \"hold_ap\": hold[\"pr_auc\"],\n",
    "    \"hold_brier\": hold[\"brier\"], \"cv_auc_mean\": res[\"roc_auc\"], \"cv_ap_mean\": res[\"pr_auc\"],\n",
    "    \"early_stopping\": False, \"best_iteration\": None,\n",
    "    \"n_trees\": N_EST, \"fit_time_s\": meta[\"fit_time_s\"],\n",
    "    \"predict_time_ms_per_1k\": meta[\"predict_time_ms_per_1k\"], \"params_json\": json.dumps(base_params)\n",
    "}\n",
    "log_summary(row)\n",
    "\n",
    "print(f\"\\n[BASELINES] PR-AUC={res['pr_auc']:.5f}  ROC-AUC={res['roc_auc']:.5f}  Brier={res['brier']:.5f}\")\n",
    "print(f\"[HOLDOUT] PR-AUC={hold['pr_auc']:.5f}  ROC-AUC={hold['roc_auc']:.5f}  Brier={hold['brier']:.5f}\")\n",
    "print(f\"Reports saved to: {REPORTS_OUT}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EXPERIMENT 1] Baseline RandomForest with default params\n",
      "\n",
      "[BASELINES] PR-AUC=0.04754  ROC-AUC=0.57511  Brier=0.03557\n",
      "[HOLDOUT] PR-AUC=0.05037  ROC-AUC=0.59361  Brier=0.03545\n",
      "Reports saved to: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "4ffa36590a8c205b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T20:40:13.220187Z",
     "start_time": "2025-09-29T19:56:51.396108Z"
    }
   },
   "source": [
    "print(f\"\\n[EXPERIMENT 2] Hyperparameter Tuning with Randomized Search\")\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100, 200, 300],\n",
    "    'clf__max_depth': [10, 20, None],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "pre = prep_for_model(X_tr_fe, selected_fe)\n",
    "clf = RandomForestClassifier(random_state=RND, n_jobs=-1)\n",
    "pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)])\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    cv=CV,\n",
    "    scoring='average_precision',\n",
    "    random_state=RND,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search.fit(X_tr_fe, y_tr)\n",
    "\n",
    "best_params = {k.replace('clf__', ''): v for k, v in random_search.best_params_.items()}\n",
    "best_score = random_search.best_score_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "print(f\"Best cross-validation PR-AUC: {best_score:.4f}\")\n",
    "\n",
    "print(\"[INFO] Training final model with best parameters...\")\n",
    "proba, hold, fi, meta = fit_final(X_tr_fe, y_tr, X_te_fe, y_te, selected_fe, model_params=best_params)\n",
    "\n",
    "report_name_tuned = \"rf_tuned\"\n",
    "pd.DataFrame({\"proba\": proba, \"y_true\": y_te.values}).to_csv(REPORTS_OUT/f\"holdout_preds_{report_name_tuned}.csv\", index=False)\n",
    "if fi is not None and not fi.empty:\n",
    "    fi.reset_index().rename(columns={\"index\":\"feature\"}).to_csv(REPORTS_OUT/f\"fi_gain_{report_name_tuned}.csv\", index=False)\n",
    "save_pr_curve(y_te.values, proba, REPORTS_OUT/f\"plot_pr_{report_name_tuned}.png\")\n",
    "save_calibration(y_te.values, proba, REPORTS_OUT/f\"plot_calibration_{report_name_tuned}.png\")\n",
    "if fi is not None: save_top20_importance(fi, REPORTS_OUT/f\"plot_fi_top20_{report_name_tuned}.png\")\n",
    "\n",
    "row = {\n",
    "    \"member\": MEMBER, \"model_name\": \"RF_Tuned\", \"encoder\": meta[\"encoder\"],\n",
    "    \"split_path\": str(split_p), \"feature_recipe\": \"selected\",\n",
    "    \"seed\": RND, \"cv_folds\": CV, \"hold_auc\": hold[\"roc_auc\"], \"hold_ap\": hold[\"pr_auc\"],\n",
    "    \"hold_brier\": hold[\"brier\"], \"cv_auc_mean\": random_search.cv_results_['mean_test_score'].max(), \"cv_ap_mean\": best_score,\n",
    "    \"early_stopping\": False, \"best_iteration\": None,\n",
    "    \"n_trees\": best_params.get('n_estimators', N_EST), \"fit_time_s\": meta[\"fit_time_s\"],\n",
    "    \"predict_time_ms_per_1k\": meta[\"predict_time_ms_per_1k\"], \"params_json\": json.dumps(best_params)\n",
    "}\n",
    "log_summary(row)\n",
    "\n",
    "print(f\"\\n[HOLDOUT] (Tuned) PR-AUC={hold['pr_auc']:.5f}  ROC-AUC={hold['roc_auc']:.5f}  Brier={hold['brier']:.5f}\")\n",
    "print(f\"Reports saved to: {REPORTS_OUT}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EXPERIMENT 2] Hyperparameter Tuning with Randomized Search\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters found: {'n_estimators': 300, 'min_samples_leaf': 2, 'max_depth': 10, 'class_weight': None}\n",
      "Best cross-validation PR-AUC: 0.0643\n",
      "[INFO] Training final model with best parameters...\n",
      "\n",
      "[HOLDOUT] (Tuned) PR-AUC=0.06903  ROC-AUC=0.63688  Brier=0.03491\n",
      "Reports saved to: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e09da94c5e51d000"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (porto_seguro_env)",
   "language": "python",
   "name": "porto_seguro_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

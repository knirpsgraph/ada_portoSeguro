{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T10:39:16.110484Z",
     "start_time": "2025-10-02T10:39:16.065960Z"
    }
   },
   "source": [
    "import os, sys, json, warnings, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, brier_score_loss, precision_recall_curve\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Pfade und Konfiguration\n",
    "if \"__file__\" in globals():\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "else:\n",
    "    ROOT = Path.cwd() if Path.cwd().name not in (\"notebooks\",\"tools\",\"tests\") else Path.cwd().parent\n",
    "sys.path.insert(0, str(ROOT))\n",
    "try:\n",
    "    from src.data_loader import load_and_save_data\n",
    "except ImportError:\n",
    "    print(\"[ERROR] 'src.data_loader' konnte nicht importiert werden. Sicherstellen, dass der Pfad stimmt.\")\n",
    "    # Platzhalter-Funktionen für Testzwecke, falls src.data_loader nicht verfügbar ist\n",
    "    def load_selected_feature_list():\n",
    "        return [f'feature_{i}' for i in range(37)] + [f'binary_feature_{i}_bin' for i in range(10)] + [f'categorical_feature_{i}_cat' for i in range(10)]\n",
    "\n",
    "    def load_and_save_data():\n",
    "        data_len = 500\n",
    "        n_features = 37\n",
    "        X = pd.DataFrame(np.random.rand(data_len, n_features), columns=[f'feature_{i}' for i in range(n_features)])\n",
    "        for i in range(10):\n",
    "            X[f'binary_feature_{i}_bin'] = np.random.randint(0, 2, data_len)\n",
    "            X[f'categorical_feature_{i}_cat'] = np.random.randint(0, 5, data_len)\n",
    "        X['target'] = np.random.randint(0, 2, data_len)\n",
    "        return X\n",
    "\n",
    "BASE_REPORTS_OUT = Path(os.getenv(\"REPORTS_OUT\") or (ROOT / \"reports_Hany/SVM\"))\n",
    "REPORTS_IN = Path(os.getenv(\"REPORTS_IN\") or (ROOT / \"reports\"))\n",
    "\n",
    "SPEED = os.getenv(\"SPEED\", \"MEDIUM\").upper().strip()\n",
    "def speed_cfg():\n",
    "    cfg = dict(CV=5, N_ITER_SEARCH=20)\n",
    "    if SPEED == \"FAST\":\n",
    "        cfg.update(CV=3, N_ITER_SEARCH=5)\n",
    "    elif SPEED == \"MEDIUM\":\n",
    "        cfg.update(CV=5, N_ITER_SEARCH=10)\n",
    "    elif SPEED == \"FULL\":\n",
    "        cfg.update(CV=5, N_ITER_SEARCH=20)\n",
    "    return cfg\n",
    "\n",
    "CFG = speed_cfg()\n",
    "RND = int(os.getenv(\"RND\", \"42\"))\n",
    "CV = int(os.getenv(\"CV\", str(CFG[\"CV\"])))\n",
    "MEMBER = os.getenv(\"MEMBER\", \"Hany\")\n",
    "N_ITER_SEARCH = int(os.getenv(\"N_ITER_SEARCH\", str(CFG[\"N_ITER_SEARCH\"])))\n",
    "\n",
    "print(f\"[SETUP] SPEED={SPEED} CV={CV} N_ITER_SEARCH={N_ITER_SEARCH} MODEL=SVM\")\n",
    "\n",
    "\n",
    "# Hilfsfunktionen\n",
    "def split_cols(cols):\n",
    "    # Trennt Spalten in kategorische, binäre und numerische.\n",
    "    cat = [c for c in cols if str(c).endswith(\"_cat\")]\n",
    "    bin_ = [c for c in cols if str(c).endswith(\"_bin\")]\n",
    "    num = [c for c in cols if c not in cat and c not in bin_ and c != \"target\"]\n",
    "    return cat, bin_, num\n",
    "\n",
    "def load_selected_feature_list():\n",
    "    f = REPORTS_IN / \"features_selected.csv\"\n",
    "    if not f.exists():\n",
    "        raise FileNotFoundError(f\"Missing {f}. Run feature-gate first.\")\n",
    "    s = pd.read_csv(f)\n",
    "    if \"raw_feature\" not in s.columns:\n",
    "        raise ValueError(\"features_selected.csv must have column 'raw_feature'.\")\n",
    "    return s[\"raw_feature\"].astype(str).tolist()\n",
    "\n",
    "class CustomFeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, selected_features):\n",
    "        self.selected_features = selected_features\n",
    "        self.bin_cols = [c for c in selected_features if str(c).endswith(\"_bin\")]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Behandle Pandas DataFrame und NumPy Array Inputs.\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_df = X.copy()\n",
    "        elif isinstance(X, np.ndarray):\n",
    "            X_df = pd.DataFrame(X, columns=[c for c in self.selected_features if c != 'target'])\n",
    "        else:\n",
    "            raise TypeError(\"Input must be a pandas DataFrame or a numpy array.\")\n",
    "\n",
    "        # Erzeuge 'missing_count'\n",
    "        if \"missing_count\" in self.selected_features and \"missing_count\" not in X_df.columns:\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X_df[\"missing_count\"] = X_df.isna().sum(axis=1)\n",
    "            else:\n",
    "                X_df[\"missing_count\"] = np.sum(np.isnan(X), axis=1)\n",
    "\n",
    "        # Erzeuge 'sum_all_bin'\n",
    "        if \"sum_all_bin\" in self.selected_features:\n",
    "            bin_cols_in_df = [c for c in self.bin_cols if c in X_df.columns]\n",
    "            if bin_cols_in_df:\n",
    "                X_df[\"sum_all_bin\"] = X_df[bin_cols_in_df].sum(axis=1)\n",
    "            else:\n",
    "                X_df[\"sum_all_bin\"] = 0\n",
    "\n",
    "        if isinstance(X, np.ndarray):\n",
    "            return X_df.values\n",
    "\n",
    "        return X_df\n",
    "\n",
    "def create_preprocessor(all_features):\n",
    "    # Preprocessor-Schritt für die Pipeline\n",
    "    cat, bin_, num = split_cols(all_features)\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]), num),\n",
    "        (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")), (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))]), cat),\n",
    "        (\"bin\", SimpleImputer(strategy=\"most_frequent\"), bin_)\n",
    "    ], remainder=\"drop\")\n",
    "    return preprocessor\n",
    "\n",
    "def get_pipeline(selected_cols, clf_model):\n",
    "    # Pipeline zusammenbauen.\n",
    "    all_features = list(set(selected_cols + [\"missing_count\", \"sum_all_bin\"]))\n",
    "    all_features = [c for c in all_features if c != 'target']\n",
    "    preprocessor = create_preprocessor(all_features)\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"feature_gen\", CustomFeatureGenerator(all_features)),\n",
    "        (\"pre\", preprocessor),\n",
    "        (\"nystroem\", Nystroem(kernel='rbf', random_state=RND)),\n",
    "        (\"clf\", clf_model)\n",
    "    ]), all_features\n",
    "\n",
    "def oof_cv(X, y, pipeline, model_params=None):\n",
    "    # OOF Kreuzvalidierung\n",
    "    skf = StratifiedKFold(n_splits=CV, shuffle=True, random_state=RND)\n",
    "    oof = np.zeros(len(y), dtype=float)\n",
    "\n",
    "    if model_params:\n",
    "        pipeline.set_params(**{f'clf__{k}': v for k, v in model_params.items()})\n",
    "\n",
    "    for tr, va in skf.split(X, y):\n",
    "        Xtr, Xva = X.iloc[tr], X.iloc[va]; ytr, yva = y.iloc[tr], y.iloc[va]\n",
    "\n",
    "        pipe_fold = clone(pipeline).fit(Xtr, ytr)\n",
    "\n",
    "        calibrator = CalibratedClassifierCV(estimator=pipe_fold, method='sigmoid', cv='prefit')\n",
    "        calibrator.fit(Xva, yva)\n",
    "        oof[va] = calibrator.predict_proba(Xva)[:, 1]\n",
    "\n",
    "    pr = average_precision_score(y, oof)\n",
    "    roc = roc_auc_score(y, oof)\n",
    "    brier = brier_score_loss(y, oof)\n",
    "    return dict(pr_auc=float(pr), roc_auc=float(roc), brier=float(brier), oof=oof)\n",
    "\n",
    "def fit_final(Xtr, ytr, Xte, yte, pipeline, model_params=None):\n",
    "    # finale Modell trainieren + bewerten.\n",
    "    if model_params:\n",
    "        pipeline.set_params(**{f'clf__{k}': v for k, v in model_params.items()})\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    pipeline.fit(Xtr, ytr)\n",
    "    fit_time_s = time.perf_counter() - t0\n",
    "\n",
    "    calibrator = CalibratedClassifierCV(estimator=pipeline, method='sigmoid', cv='prefit')\n",
    "    calibrator.fit(Xtr, ytr)\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    proba = calibrator.predict_proba(Xte)[:, 1]\n",
    "    pred_ms_per_1k = 1000 * (time.perf_counter() - t1) / (len(Xte) if len(Xte) > 0 else 1)\n",
    "\n",
    "    try:\n",
    "        if isinstance(pipeline.named_steps['clf'], LinearSVC):\n",
    "            n_components = pipeline.named_steps['nystroem'].n_components\n",
    "            coefs = pipeline.named_steps['clf'].coef_[0]\n",
    "            fi = pd.Series(coefs, index=[f'nystroem_component_{i}' for i in range(n_components)], name=\"gain\").abs().sort_values(ascending=False)\n",
    "        else:\n",
    "            fi = None\n",
    "    except (NotFittedError, KeyError):\n",
    "        fi = None\n",
    "\n",
    "    meta = {\n",
    "        \"encoder\": \"OHE + StandardScaler + Nystroem + Calibrator\",\n",
    "        \"fit_time_s\": float(fit_time_s),\n",
    "        \"predict_time_ms_per_1k\": float(pred_ms_per_1k),\n",
    "        \"params\": model_params\n",
    "    }\n",
    "    hold = dict(pr_auc=float(average_precision_score(yte, proba)), roc_auc=float(roc_auc_score(yte, proba)), brier=float(brier_score_loss(yte, proba)))\n",
    "\n",
    "    return proba, hold, fi, meta\n",
    "\n",
    "# Berichtsfunktionen\n",
    "def save_pr_curve(y_true, proba, out_path):\n",
    "    # Precision-Recall-Kurve.\n",
    "    prec, rec, _ = precision_recall_curve(y_true, proba); ap = average_precision_score(y_true, proba)\n",
    "    plt.figure(figsize=(7,5)); plt.plot(rec, prec, label=f'AP={ap:.4f}')\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall'); plt.xlim([0,1]); plt.ylim([0,1]); plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def save_calibration(y_true, proba, out_path):\n",
    "    # Kalibrierungskurve.\n",
    "    prob_true, prob_pred = calibration_curve(y_true, proba, n_bins=20, strategy=\"quantile\")\n",
    "    plt.figure(figsize=(6,6)); plt.plot([0,1],[0,1],'--',label='Perfect')\n",
    "    plt.plot(prob_pred, prob_true, marker='o', label='Model')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Observed'); plt.title('Calibration')\n",
    "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def save_top20_importance(fi: pd.Series, out_path):\n",
    "    # Balkendiagramm der 20 wichtigsten Features.\n",
    "    if fi is None or fi.empty:\n",
    "        print(\"[INFO] Feature Importance nicht verfügbar oder leer.\")\n",
    "        return\n",
    "    top = fi.head(20).iloc[::-1]\n",
    "    plt.figure(figsize=(8,6)); plt.barh(top.index, top.values)\n",
    "    plt.xlabel('Absoluter Koeffizient'); plt.title('Top-20 Feature Importance (LinearSVC Koeffizienten)')\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def log_summary(row, filename=\"team_model_summary.csv\"):\n",
    "    # Modellzusammenfassung\n",
    "    out_csv = BASE_REPORTS_OUT / filename\n",
    "    pd.DataFrame([row]).to_csv(out_csv, mode=\"a\", index=False, header=not out_csv.exists())\n",
    "\n",
    "def plot_svm_metrics_comparison(metrics_data, out_path):\n",
    "    # Vergleich der SVM-Modelle\n",
    "    df_metrics = pd.DataFrame(metrics_data)\n",
    "    df_metrics.set_index(\"model_name\", inplace=True)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    df_metrics['hold_ap'].plot(kind='barh', ax=axes[0], title='PR-AUC')\n",
    "    df_metrics['hold_auc'].plot(kind='barh', ax=axes[1], title='ROC-AUC')\n",
    "    df_metrics['hold_brier'].plot(kind='barh', ax=axes[2], title='Brier-Score')\n",
    "    for ax in axes:\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "        ax.set_ylabel('')\n",
    "        ax.tick_params(axis='y', rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] SVM-Metriken-Vergleichsplot wurde gespeichert: {out_path}\")\n",
    "\n",
    "def plot_svm_proba_distributions(out_dir, out_path):\n",
    "    # KDE-Plot -- Vorhersagewahrscheinlichkeiten.\n",
    "    try:\n",
    "        df_baseline = pd.read_csv(out_dir / \"holdout_preds_baseline.csv\")\n",
    "        df_tuned = pd.read_csv(out_dir / \"holdout_preds_tuned_nystroem_calibrated.csv\")\n",
    "        df_baseline['model'] = 'SVM_Baseline'\n",
    "        df_tuned['model'] = 'SVM_Tuned'\n",
    "        df_combined = pd.concat([df_baseline, df_tuned], ignore_index=True)\n",
    "        df_combined['legend_label'] = df_combined.apply(\n",
    "            lambda row: f\"{row['model']} - Klasse {int(row['y_true'])}\", axis=1\n",
    "        )\n",
    "        plt.figure(figsize=(14, 9))\n",
    "        sns.kdeplot(\n",
    "            data=df_combined,\n",
    "            x='proba',\n",
    "            hue='legend_label',\n",
    "            fill=True,\n",
    "            alpha=0.6,\n",
    "            common_norm=False,\n",
    "            legend=True\n",
    "        )\n",
    "        plt.title('Verteilung der Vorhersagewahrscheinlichkeiten: SVM-Modelle')\n",
    "        plt.xlabel('Vorhergesagte Wahrscheinlichkeit')\n",
    "        plt.ylabel('Dichte')\n",
    "        plt.legend(title='Modell und Klasse')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_path, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"[INFO] SVM-Vorhersage-Verteilungsplot wurde gespeichert: {out_path}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Fehler: Eine der benötigten Dateien wurde nicht gefunden. {e}\")\n",
    "\n",
    "def plot_pr_curve_all(predictions, y_true, out_path):\n",
    "    # Vergleicht die Precision-Recall-Kurven mehrerer Modelle in einem Plot.\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for model_name, proba in predictions.items():\n",
    "        prec, rec, _ = precision_recall_curve(y_true, proba)\n",
    "        ap_score = average_precision_score(y_true, proba)\n",
    "        plt.plot(rec, prec, label=f'{model_name} (AP={ap_score:.4f})')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Vergleich der Precision-Recall-Kurven')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Precision-Recall-Kurven-Vergleichsplot wurde gespeichert: {out_path}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SETUP] SPEED=MEDIUM CV=5 N_ITER_SEARCH=10 MODEL=SVM\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "9ea5c74a-c230-468f-b0b9-ed43f385e904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T10:56:41.486530600Z",
     "start_time": "2025-10-02T10:39:17.155766Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f\"[SETUP] Starting data loading and splitting.\")\n",
    "    split_p = REPORTS_IN / \"split_indices.json\"\n",
    "    feats_p = REPORTS_IN / \"features_selected.csv\"\n",
    "    assert split_p.exists() and feats_p.exists(), \"Missing split and/or features files in reports.\"\n",
    "\n",
    "    split = json.loads(split_p.read_text())\n",
    "    selected = load_selected_feature_list()\n",
    "\n",
    "    df = load_and_save_data().replace(-1, np.nan)\n",
    "    X_tr_all = df.loc[split[\"train\"]].drop(columns=[\"target\"])\n",
    "    y_tr = df.loc[split[\"train\"], \"target\"].astype(int)\n",
    "    X_te_all = df.loc[split[\"test\"]].drop(columns=[\"target\"])\n",
    "    y_te = df.loc[split[\"test\"], \"target\"].astype(int)\n",
    "\n",
    "    selected_fe = selected.copy()\n",
    "    print(\"[SETUP] Data loaded and split successfully.\")\n",
    "\n",
    "    REPORTS_OUT_MODEL = BASE_REPORTS_OUT\n",
    "    REPORTS_OUT_MODEL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"\\n[EXPERIMENT 1] Baseline LinearSVC with Nystroem using default params\")\n",
    "    base_params = {'C': 1.0, 'class_weight': 'balanced'}\n",
    "    clf_model_baseline = LinearSVC(random_state=RND, max_iter=8000, dual=False, **base_params)\n",
    "\n",
    "    pipe_baseline, all_features = get_pipeline(selected_fe, clf_model_baseline)\n",
    "    pipe_baseline.set_params(nystroem__gamma=0.1, nystroem__n_components=1000)\n",
    "\n",
    "    res_baseline = oof_cv(X_tr_all, y_tr, pipe_baseline)\n",
    "    proba_baseline, hold_baseline, fi_baseline, meta_baseline = fit_final(X_tr_all, y_tr, X_te_all, y_te, pipe_baseline)\n",
    "\n",
    "    report_name_baseline = \"baseline\"\n",
    "    pd.DataFrame({\"oof\": res_baseline[\"oof\"]}).to_csv(REPORTS_OUT_MODEL / f\"oof_{report_name_baseline}.csv\", index=False)\n",
    "    pd.DataFrame({\"proba\": proba_baseline, \"y_true\": y_te.values}).to_csv(REPORTS_OUT_MODEL / f\"holdout_preds_{report_name_baseline}.csv\", index=False)\n",
    "    if fi_baseline is not None:\n",
    "        fi_baseline.reset_index().rename(columns={\"index\": \"feature\"}).to_csv(REPORTS_OUT_MODEL / f\"fi_gain_{report_name_baseline}.csv\", index=False)\n",
    "    save_pr_curve(y_te.values, proba_baseline, REPORTS_OUT_MODEL / f\"plot_pr_{report_name_baseline}.png\")\n",
    "    save_calibration(y_te.values, proba_baseline, REPORTS_OUT_MODEL / f\"plot_calibration_{report_name_baseline}.png\")\n",
    "    if fi_baseline is not None:\n",
    "        save_top20_importance(fi_baseline, REPORTS_OUT_MODEL / f\"plot_fi_top20_{report_name_baseline}.png\")\n",
    "\n",
    "    row_baseline = {\n",
    "        \"member\": MEMBER, \"model_name\": \"SVM_Baseline\", \"encoder\": meta_baseline[\"encoder\"],\n",
    "        \"split_path\": str(split_p), \"feature_recipe\": \"selected_fe\",\n",
    "        \"seed\": RND, \"cv_folds\": CV, \"hold_auc\": hold_baseline[\"roc_auc\"], \"hold_ap\": hold_baseline[\"pr_auc\"],\n",
    "        \"hold_brier\": hold_baseline[\"brier\"], \"cv_auc_mean\": res_baseline[\"roc_auc\"], \"cv_ap_mean\": res_baseline[\"pr_auc\"],\n",
    "        \"early_stopping\": False, \"best_iteration\": None,\n",
    "        \"n_trees\": None, \"fit_time_s\": meta_baseline[\"fit_time_s\"],\n",
    "        \"predict_time_ms_per_1k\": meta_baseline[\"predict_time_ms_per_1k\"], \"params_json\": json.dumps(base_params)\n",
    "    }\n",
    "    log_summary(row_baseline)\n",
    "    print(f\"\\n[BASELINE] PR-AUC={res_baseline['pr_auc']:.5f}  ROC-AUC={res_baseline['roc_auc']:.5f}  Brier={res_baseline['brier']:.5f}\")\n",
    "    print(f\"[HOLDOUT] PR-AUC={hold_baseline['pr_auc']:.5f}  ROC-AUC={hold_baseline['roc_auc']:.5f}  Brier={hold_baseline['brier']:.5f}\")\n",
    "    print(f\"Reports saved to: {REPORTS_OUT_MODEL}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SETUP] Starting data loading and splitting.\n",
      "Loading dataset from local file: D:\\AdA_Project25\\158_portoSeguro\\data\\raw\\porto_seguro_safe_driver_prediction.csv\n",
      "Dataset loaded successfully.\n",
      "[SETUP] Data loaded and split successfully.\n",
      "\n",
      "[EXPERIMENT 1] Baseline LinearSVC with Nystroem using default params\n",
      "\n",
      "[BASELINE] PR-AUC=0.05538  ROC-AUC=0.61295  Brier=0.03503\n",
      "[HOLDOUT] PR-AUC=0.05998  ROC-AUC=0.62776  Brier=0.03500\n",
      "Reports saved to: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\\SVM\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T11:21:21.424817Z",
     "start_time": "2025-10-02T10:57:49.889679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\n[EXPERIMENT 2] Running RandomizedSearchCV for Nystroem tuning...\")\n",
    "param_grid = {\n",
    "    'nystroem__gamma': [0.01, 0.1, 1],\n",
    "    'nystroem__n_components': [100, 250, 500],\n",
    "    'clf__C': [0.1, 1, 10]\n",
    "}\n",
    "clf_model_search = LinearSVC(random_state=RND, class_weight='balanced', max_iter=8000, dual=False)\n",
    "pipe_search, _ = get_pipeline(selected_fe, clf_model_search)\n",
    "calibrated_pipe_search = CalibratedClassifierCV(estimator=pipe_search, method='sigmoid', cv=CV)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=calibrated_pipe_search,\n",
    "    param_distributions={f'estimator__{k}': v for k, v in param_grid.items() if k.startswith('clf__') or k.startswith('nystroem__')},\n",
    "    n_iter=N_ITER_SEARCH,\n",
    "    cv=CV,\n",
    "    scoring='average_precision',\n",
    "    random_state=RND,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search.fit(X_tr_all, y_tr)\n",
    "best_params_tuned = {k.replace('estimator__', ''): v for k, v in random_search.best_params_.items()}\n",
    "best_score_tuned = random_search.best_score_\n",
    "best_pipeline_tuned = random_search.best_estimator_\n",
    "\n",
    "print(f\"\\nBest Parameters found: {best_params_tuned}\")\n",
    "print(f\"Best PR-AUC from CV: {best_score_tuned:.4f}\")\n",
    "\n",
    "t0_pred = time.perf_counter()\n",
    "proba_tuned = best_pipeline_tuned.predict_proba(X_te_all)[:, 1]\n",
    "pred_ms_per_1k_tuned = 1000 * (time.perf_counter() - t0_pred) / (len(X_te_all) if len(X_te_all) > 0 else 1)\n",
    "\n",
    "hold_tuned = {\n",
    "    \"pr_auc\": average_precision_score(y_te, proba_tuned),\n",
    "    \"roc_auc\": roc_auc_score(y_te, proba_tuned),\n",
    "    \"brier\": brier_score_loss(y_te, proba_tuned),\n",
    "}\n",
    "\n",
    "try:\n",
    "    best_clf = best_pipeline_tuned.estimator.named_steps['clf']\n",
    "    nystroem_features = best_pipeline_tuned.estimator.named_steps['nystroem'].n_components\n",
    "    fi_tuned = pd.Series(best_clf.coef_[0], index=[f'nystroem_component_{i}' for i in range(nystroem_features)], name=\"gain\").abs().sort_values(ascending=False)\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] Feature Importance konnte nicht extrahiert werden: {e}\")\n",
    "    fi_tuned = None\n",
    "\n",
    "report_name_tuned = \"tuned_nystroem_calibrated\"\n",
    "pd.DataFrame({\"proba\": proba_tuned, \"y_true\": y_te.values}).to_csv(REPORTS_OUT_MODEL / f\"holdout_preds_{report_name_tuned}.csv\", index=False)\n",
    "if fi_tuned is not None:\n",
    "    fi_tuned.reset_index().rename(columns={\"index\": \"feature\"}).to_csv(REPORTS_OUT_MODEL / f\"fi_gain_{report_name_tuned}.csv\", index=False)\n",
    "save_pr_curve(y_te.values, proba_tuned, REPORTS_OUT_MODEL / f\"plot_pr_{report_name_tuned}.png\")\n",
    "save_calibration(y_te.values, proba_tuned, REPORTS_OUT_MODEL / f\"plot_calibration_{report_name_tuned}.png\")\n",
    "if fi_tuned is not None:\n",
    "    save_top20_importance(fi_tuned, REPORTS_OUT_MODEL / f\"plot_fi_top20_{report_name_tuned}.png\")\n",
    "\n",
    "row_tuned = {\n",
    "    \"member\": MEMBER, \"model_name\": \"SVM_Tuned\", \"encoder\": \"OHE + StandardScaler + Nystroem + Calibrator\",\n",
    "    \"split_path\": str(split_p), \"feature_recipe\": \"selected_fe\",\n",
    "    \"seed\": RND, \"cv_folds\": CV, \"hold_auc\": hold_tuned[\"roc_auc\"], \"hold_ap\": hold_tuned[\"pr_auc\"],\n",
    "    \"hold_brier\": hold_tuned[\"brier\"], \"cv_auc_mean\": best_score_tuned, \"cv_ap_mean\": best_score_tuned,\n",
    "    \"early_stopping\": False, \"best_iteration\": None,\n",
    "    \"n_trees\": None, \"fit_time_s\": 0,\n",
    "    \"predict_time_ms_per_1k\": pred_ms_per_1k_tuned, \"params_json\": json.dumps(best_params_tuned)\n",
    "}\n",
    "log_summary(row_tuned)\n",
    "\n",
    "print(f\"\\n[TUNED] PR-AUC from CV: {best_score_tuned:.5f}\")\n",
    "print(f\"[HOLDOUT] PR-AUC: {hold_tuned['pr_auc']:.5f} ROC-AUC: {hold_tuned['roc_auc']:.5f} Brier: {hold_tuned['brier']:.5f}\")\n",
    "print(f\"Reports saved to: {REPORTS_OUT_MODEL}\")"
   ],
   "id": "d66f3baddc0703a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EXPERIMENT 2] Running RandomizedSearchCV for Nystroem tuning...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Best Parameters found: {'nystroem__n_components': 100, 'nystroem__gamma': 0.01, 'clf__C': 0.1}\n",
      "Best PR-AUC from CV: 0.0618\n",
      "[WARN] Feature Importance konnte nicht extrahiert werden: 'LinearSVC' object has no attribute 'coef_'\n",
      "\n",
      "[TUNED] PR-AUC from CV: 0.06179\n",
      "[HOLDOUT] PR-AUC: 0.06567 ROC-AUC: 0.63904 Brier: 0.03489\n",
      "Reports saved to: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\\SVM\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T11:21:40.225161Z",
     "start_time": "2025-10-02T11:21:37.898681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "REPORTS_OUT = BASE_REPORTS_OUT\n",
    "\n",
    "\n",
    "svm_metrics = [\n",
    "    {\"model_name\": \"SVM_Baseline\", \"hold_ap\": hold_baseline[\"pr_auc\"], \"hold_auc\": hold_baseline[\"roc_auc\"], \"hold_brier\": hold_baseline[\"brier\"]},\n",
    "    {\"model_name\": \"SVM_Tuned\", \"hold_ap\": hold_tuned[\"pr_auc\"], \"hold_auc\": hold_tuned[\"roc_auc\"], \"hold_brier\": hold_tuned[\"brier\"]}\n",
    "]\n",
    "\n",
    "plot_svm_metrics_comparison(svm_metrics, REPORTS_OUT_MODEL / \"plot_svm_metrics_comparison.png\")\n",
    "plot_svm_proba_distributions(REPORTS_OUT_MODEL, REPORTS_OUT_MODEL / \"plot_svm_proba_distributions.png\")\n",
    "\n",
    "# Plotten der PR-Kurven beider Modelle\n",
    "print(\"\\n[INFO] Generiere Vergleichsplot für PR-Kurven...\")\n",
    "preds_for_plot = {\n",
    "    'SVM_Baseline': proba_baseline,\n",
    "    'SVM_Tuned': proba_tuned\n",
    "}\n",
    "plot_pr_curve_all(preds_for_plot, y_te, REPORTS_OUT_MODEL / \"plot_pr_curve_comparison.png\")\n"
   ],
   "id": "7cc70fcb78767b85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] SVM-Metriken-Vergleichsplot wurde gespeichert: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\\SVM\\plot_svm_metrics_comparison.png\n",
      "[INFO] SVM-Vorhersage-Verteilungsplot wurde gespeichert: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\\SVM\\plot_svm_proba_distributions.png\n",
      "\n",
      "[INFO] Generiere Vergleichsplot für PR-Kurven...\n",
      "[INFO] Precision-Recall-Kurven-Vergleichsplot wurde gespeichert: D:\\AdA_Project25\\158_portoSeguro\\reports_Hany\\SVM\\plot_pr_curve_comparison.png\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "53fb23814b3bf5ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
